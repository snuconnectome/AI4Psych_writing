{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ë…¼ë¬¸ Introduction ìž‘ì„± ìžë™í™” íŒŒì´í”„ë¼ì¸ (Advanced)\n",
    "\n",
    "## ðŸ“– ê°œìš”\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ PubMedì—ì„œ ê´€ë ¨ ë…¼ë¬¸ì„ ê²€ìƒ‰í•˜ê³ , ì´ë¥¼ ë¶„ì„í•˜ì—¬ ë…¼ë¬¸ì˜ Introduction ì„¹ì…˜ì„ ìžë™ìœ¼ë¡œ ìž‘ì„±í•˜ëŠ” ê³ ê¸‰ íŒŒì´í”„ë¼ì¸ìž…ë‹ˆë‹¤. ì‚¬ìš©ìžê°€ ì§ì ‘ ìž‘ì„±í•œ Introductionê³¼ ìžë™ ìƒì„± ê²°ê³¼ë¥¼ í†µí•©í•˜ëŠ” ê¸°ëŠ¥ë„ í¬í•¨ë˜ì–´ ìžˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "## ðŸŽ¯ íŒŒì´í”„ë¼ì¸ êµ¬ì„±\n",
    "\n",
    "### **Agent 0: í† í”½ ì •ì˜ ì—ì´ì „íŠ¸**\n",
    "- **ì—­í• **: ì‚¬ìš©ìžë¡œë¶€í„° ì—°êµ¬ ì£¼ì œë¥¼ ë°›ì•„ì„œ êµ¬ì¡°í™”ëœ ì •ë³´ë¡œ ë³€í™˜\n",
    "- **ìž…ë ¥**: ìžìœ ë¡œìš´ í˜•íƒœì˜ ì—°êµ¬ ì£¼ì œ ì„¤ëª…\n",
    "- **ì¶œë ¥**: ë©”ì¸ í† í”½, ì—°êµ¬ ë¶„ì•¼, ë©”ì†Œë“œ, í‚¤ì›Œë“œ, PubMed ê²€ìƒ‰ ì¿¼ë¦¬ ì œì•ˆ\n",
    "- **ëª©ì **: íš¨ê³¼ì ì¸ ë¬¸í—Œ ê²€ìƒ‰ì„ ìœ„í•œ êµ¬ì¡°í™”ëœ ì •ë³´ ìƒì„±\n",
    "\n",
    "### **Agent 1: PubMed ê²€ìƒ‰ ì—ì´ì „íŠ¸ (v2)**\n",
    "- **ì—­í• **: PubMedì—ì„œ ë…¼ë¬¸ì„ ê²€ìƒ‰í•˜ê³  APA 7th í˜•ì‹ìœ¼ë¡œ ì •ë¦¬\n",
    "- **ìž…ë ¥**: í† í”½ ì •ì˜ ê²°ê³¼, ê²€ìƒ‰ ì¿¼ë¦¬\n",
    "- **ì¶œë ¥**: ë…¼ë¬¸ ë¦¬ìŠ¤íŠ¸, APA í˜•ì‹ ë ˆí¼ëŸ°ìŠ¤, ì €ìž/ë…„ë„ ì •ë³´, í‘œ ë° JSON íŒŒì¼\n",
    "- **ëª©ì **: ì¸ìš© ê°€ëŠ¥í•œ í˜•íƒœë¡œ ê´€ë ¨ ë…¼ë¬¸ ìˆ˜ì§‘\n",
    "- **íŠ¹ì§•**:\n",
    "  - ìƒì˜í•™ ì •ë³´ ì „ë¬¸ê°€ íŽ˜ë¥´ì†Œë‚˜ë¡œ ìµœì í™”ëœ ì¿¼ë¦¬ ìƒì„±\n",
    "  - ì—¬ëŸ¬ ê²€ìƒ‰ ì¿¼ë¦¬ ì œì•ˆ ë° ì‚¬ìš©ìž ì„ íƒ (ëŒ€í™”í˜•/ìžë™ ëª¨ë“œ)\n",
    "  - APA 7th edition í˜•ì‹ ìžë™ ë³€í™˜\n",
    "  - ê° ë…¼ë¬¸ì— APA í˜•ì‹ ë§¤í•‘\n",
    "  - CSV/Excel/JSON íŒŒì¼ë¡œ ì €ìž¥\n",
    "\n",
    "### **Agent 2: Introduction ìž‘ì„± ì—ì´ì „íŠ¸**\n",
    "- **ì—­í• **: ê²€ìƒ‰ëœ ë…¼ë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ Introduction ì´ˆì•ˆ ìž‘ì„±\n",
    "- **ìž…ë ¥**: í† í”½ ì •ì˜, ê²€ìƒ‰ëœ ë…¼ë¬¸ ì •ë³´\n",
    "- **ì¶œë ¥**: êµ¬ì¡°í™”ëœ Introduction í…ìŠ¤íŠ¸\n",
    "- **êµ¬ì¡°**:\n",
    "  1. ë©”ì¸ í† í”½ ì†Œê°œ ë° ë°°ê²½ (2-3 ë¬¸ë‹¨)\n",
    "  2. í˜„ìž¬ ì—°êµ¬ ë™í–¥ (2-3 ë¬¸ë‹¨) - ë…¼ë¬¸ ì¸ìš© í¬í•¨\n",
    "  3. Research gap ì‹ë³„ (1-2 ë¬¸ë‹¨)\n",
    "  4. í˜„ìž¬ ì—°êµ¬ì˜ í•„ìš”ì„± (1-2 ë¬¸ë‹¨)\n",
    "- **íŠ¹ì§•**: (ì €ìž, ë…„ë„) í˜•ì‹ìœ¼ë¡œ ë³¸ë¬¸ì— ì¸ìš©\n",
    "\n",
    "### **Agent 3: ë…¼ë¦¬ ì ê²€ ì—ì´ì „íŠ¸**\n",
    "- **ì—­í• **: ìž‘ì„±ëœ Introductionì˜ ë…¼ë¦¬ì  ì¼ê´€ì„± ê²€ì¦\n",
    "- **ìž…ë ¥**: í† í”½ ì •ì˜, Agent 2 ìž‘ì„± Introduction\n",
    "- **ì¶œë ¥**: ë…¼ë¦¬ ì ê²€ ë³´ê³ ì„œ\n",
    "- **ê¸°ëŠ¥**:\n",
    "  - ê° ë¬¸ìž¥ì˜ ë©”ì¸ í† í”½ê³¼ì˜ ì—°ê´€ì„± ì ìˆ˜ (0-10)\n",
    "  - ìž„ê³„ê°’ ì´í•˜ ë¬¸ìž¥ ìžë™ ê°ì§€\n",
    "  - ë¬¸ì œì  ë° ê°œì„  ë°©ì•ˆ ì œì‹œ\n",
    "- **ëª©ì **: ì£¼ì œì—ì„œ ë²—ì–´ë‚œ ë‚´ìš© ì‹ë³„\n",
    "\n",
    "### **Agent 3.5: ë…¼ë¦¬ ì ê²€ ê¸°ë°˜ ìž¬ìž‘ì„± ì—ì´ì „íŠ¸**\n",
    "- **ì—­í• **: Agent 3ì˜ í”¼ë“œë°±ì„ ì‹¤ì œë¡œ ì ìš©í•˜ì—¬ Introduction ìž¬ìž‘ì„±\n",
    "- **ìž…ë ¥**: Agent 2 ì´ˆì•ˆ, Agent 3 ë…¼ë¦¬ ì ê²€ ë³´ê³ ì„œ\n",
    "- **ì¶œë ¥**: ë…¼ë¦¬ì ìœ¼ë¡œ ê°œì„ ëœ Introduction\n",
    "- **ê¸°ëŠ¥**:\n",
    "  - ìž„ê³„ê°’ ì´í•˜ ë¬¸ìž¥ ìˆ˜ì •/ì œê±°\n",
    "  - ì£¼ì œì™€ì˜ ì—°ê´€ì„± ê°•í™”\n",
    "  - ë…¼ë¦¬ íë¦„ ê°œì„ \n",
    "  - ë¬¸ë‹¨ ê°„ ì—°ê²° ê°•í™”\n",
    "- **ì ìš© ì „ëžµ**:\n",
    "  - ì ìˆ˜ 0-3: ì‚­ì œ ë˜ëŠ” ì™„ì „ížˆ ìž¬ìž‘ì„±\n",
    "  - ì ìˆ˜ 4-6: ì£¼ì œì™€ì˜ ì—°ê´€ì„± ê°•í™”\n",
    "  - ì ìˆ˜ 7-10: ìœ ì§€ (í•„ìš”ì‹œ ë¯¸ì„¸ ì¡°ì •)\n",
    "- **ëª©ì **: Agent 3ëŠ” ë¬¸ì œë¥¼ ì‹ë³„, Agent 3.5ëŠ” ì‹¤ì œë¡œ í•´ê²°\n",
    "\n",
    "### **Agent 4: ì‚¬ìš©ìž-íŒŒì´í”„ë¼ì¸ í†µí•© ì—ì´ì „íŠ¸**\n",
    "- **ì—­í• **: ì‚¬ìš©ìžê°€ ì§ì ‘ ìž‘ì„±í•œ Introductionê³¼ íŒŒì´í”„ë¼ì¸ ê²°ê³¼ í†µí•©\n",
    "- **ìž…ë ¥**: ì‚¬ìš©ìž ìž‘ì„± Introduction, Agent 3.5 ê²°ê³¼, Agent 1 ê²€ìƒ‰ ê²°ê³¼\n",
    "- **ì¶œë ¥**: í†µí•©ëœ Introduction\n",
    "- **í•µì‹¬ ì›ì¹™**:\n",
    "  - **ì‚¬ìš©ìž ìž‘ì„±ë³¸ì´ ìµœìš°ì„ ** (ë…¼ë¦¬ ì „ê°œ, êµ¬ì¡°, í†¤ ìœ ì§€)\n",
    "  - íŒŒì´í”„ë¼ì¸ ê²°ê³¼ëŠ” **ë³´ì¡° ìˆ˜ë‹¨** (ì¸ìš©, ì¦ê±° ì¶”ê°€)\n",
    "  - ì‚¬ìš©ìžì˜ ë‚´ìš©ì„ ìž¬ë°°ì¹˜í•˜ê±°ë‚˜ ì‚­ì œí•˜ì§€ ì•ŠìŒ\n",
    "- **ê¸°ëŠ¥**:\n",
    "  - ì‚¬ìš©ìž í…ìŠ¤íŠ¸ì— ê´€ë ¨ ì¸ìš© ì¶”ê°€\n",
    "  - ì—°êµ¬ ê²°ê³¼ë¡œ ì£¼ìž¥ ë’·ë°›ì¹¨\n",
    "  - ìžì—°ìŠ¤ëŸ¬ìš´ ë¬¸ë‹¨ ì—°ê²°\n",
    "- **ëª©ì **: ì‚¬ìš©ìžì˜ ì˜ë„ë¥¼ ì¡´ì¤‘í•˜ë©´ì„œ í•™ìˆ ì  ì™„ì„±ë„ í–¥ìƒ\n",
    "\n",
    "### **Agent 5: ìµœì¢… ë¬¸ì²´ ì ê²€ ì—ì´ì „íŠ¸**\n",
    "- **ì—­í• **: í†µí•©ëœ Introductionì— í•™ìˆ ì  ê¸€ì“°ê¸° ê·œì¹™ ì ìš©\n",
    "- **ìž…ë ¥**: Agent 4 í†µí•© ê²°ê³¼ (ë˜ëŠ” Agent 3.5, Agent 2)\n",
    "- **ì¶œë ¥**: ì¶œíŒ ê°€ëŠ¥í•œ ìˆ˜ì¤€ì˜ ìµœì¢… Introduction\n",
    "- **ì ìš© ê·œì¹™** (`02_translate.py`, `03_revise.py` ì°¸ê³ ):\n",
    "  - ë™ì‚¬ ì¤‘ì‹¬ í‘œí˜„ (ëª…ì‚¬í˜• â†’ ë™ì‚¬í˜•)\n",
    "  - ì£¼ì–´-ë™ì‚¬ ê·¼ì ‘ ë°°ì¹˜\n",
    "  - ëŠ¥ë™íƒœ ìš°ì„  ì‚¬ìš©\n",
    "  - ê°„ê²°í•œ í•™ìˆ  í‘œí˜„\n",
    "  - ë¬¸ë‹¨ ì‘ì§‘ì„± ê°œì„ \n",
    "- **ëª©ì **: í•™ìˆ  ë…¼ë¬¸ì— ì í•©í•œ ìµœì¢… ë¬¸ì²´ ì™„ì„±\n",
    "\n",
    "## ðŸ”„ íŒŒì´í”„ë¼ì¸ íë¦„\n",
    "\n",
    "```\n",
    "Agent 0 (Topic Definition)\n",
    "    â†“\n",
    "Agent 1 (PubMed Search & APA Format) â†’ í‘œ/JSON ì €ìž¥\n",
    "    â†“\n",
    "Agent 2 (Draft Introduction) â†’ ì´ˆì•ˆ ìž‘ì„±\n",
    "    â†“\n",
    "Agent 3 (Logic Check) â†’ ë¬¸ì œ ì‹ë³„\n",
    "    â†“\n",
    "Agent 3.5 (Logic Revision) â†’ ë¬¸ì œ í•´ê²°\n",
    "    â†“\n",
    "Agent 4 (User-Pipeline Integration) â†’ ì‚¬ìš©ìž ìž‘ì„±ë³¸ í†µí•© â­\n",
    "    â†“\n",
    "Agent 5 (Final Style Check) â†’ ë¬¸ì²´ ê°œì„ \n",
    "    â†“\n",
    "Final Introduction (ì¶œíŒ ê°€ëŠ¥ ìˆ˜ì¤€)\n",
    "```\n",
    "\n",
    "## ðŸ”§ ì§€ì› ëª¨ë¸\n",
    "- **OpenAI**: GPT-4, GPT-4o\n",
    "- **Google Gemini**: Gemini-2.0-flash-exp, Gemini-2.5-flash\n",
    "\n",
    "## ðŸ“ ì‚¬ìš© ë°©ë²•\n",
    "\n",
    "### ê¸°ë³¸ ì‚¬ìš© (ìžë™ ìƒì„±):\n",
    "1. **Agent 0 â†’ 1 â†’ 2 â†’ 3 â†’ 3.5 â†’ 5** ìˆœì„œë¡œ ì‹¤í–‰\n",
    "2. Agent 4ëŠ” ê±´ë„ˆë›°ê³  Agent 5ì—ì„œ Agent 3.5 ê²°ê³¼ë¥¼ ìž…ë ¥ìœ¼ë¡œ ì‚¬ìš©\n",
    "\n",
    "### ê³ ê¸‰ ì‚¬ìš© (ì‚¬ìš©ìž ìž‘ì„±ë³¸ í†µí•©):\n",
    "1. **Agent 0 â†’ 1 â†’ 2 â†’ 3 â†’ 3.5** ì‹¤í–‰\n",
    "2. **ì‚¬ìš©ìžê°€ ì§ì ‘ Introduction ìž‘ì„±**\n",
    "3. **Agent 4** ì‹¤í–‰: ì‚¬ìš©ìž ìž‘ì„±ë³¸ + íŒŒì´í”„ë¼ì¸ ê²°ê³¼ í†µí•©\n",
    "4. **Agent 5** ì‹¤í–‰: ìµœì¢… ë¬¸ì²´ ì ê²€\n",
    "\n",
    "### ì£¼ì˜ì‚¬í•­:\n",
    "- ê° ì…€ì„ **ìˆœì„œëŒ€ë¡œ** ì‹¤í–‰í•˜ì„¸ìš”\n",
    "- ê° ì—ì´ì „íŠ¸ ì‹¤í–‰ í›„ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”\n",
    "- ëª¨ë“  ê²°ê³¼ëŠ” íƒ€ìž„ìŠ¤íƒ¬í”„ê°€ í¬í•¨ëœ íŒŒì¼ë¡œ ìžë™ ì €ìž¥ë©ë‹ˆë‹¤\n",
    "- ì—ì´ì „íŠ¸ ê°„ í†µì‹ ì€ **íŒŒì¼ ê¸°ë°˜**ìœ¼ë¡œ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤\n",
    "\n",
    "## ðŸ’¾ ìƒì„±ë˜ëŠ” íŒŒì¼\n",
    "- `agent0_topic_definition_[timestamp].txt` - í† í”½ ì •ì˜\n",
    "- `papers_search_[timestamp].json` - ê²€ìƒ‰ ê²°ê³¼ (JSON)\n",
    "- `papers_table_[timestamp].csv` - ê²€ìƒ‰ ê²°ê³¼ (CSV í‘œ)\n",
    "- `papers_table_[timestamp].xlsx` - ê²€ìƒ‰ ê²°ê³¼ (Excel í‘œ)\n",
    "- `agent2_introduction_draft_[timestamp].txt` - ì´ˆì•ˆ\n",
    "- `agent3_logic_report_[timestamp].txt` - ë…¼ë¦¬ ì ê²€ ë³´ê³ ì„œ\n",
    "- `agent3.5_logic_revised_[timestamp].txt` - ë…¼ë¦¬ ê°œì„  ë²„ì „\n",
    "- `agent4_integrated_[timestamp].txt` - ì‚¬ìš©ìž í†µí•© ë²„ì „\n",
    "- `agent5_final_[timestamp].txt` - ìµœì¢… ë¬¸ì²´ ì ê²€ ë²„ì „\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1. í™˜ê²½ ì„¤ì •\n",
    "\n",
    "## ðŸ“¦ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "\n",
    "ì´ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•˜ê¸° ìœ„í•´ ë‹¤ìŒ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì´ í•„ìš”í•©ë‹ˆë‹¤:\n",
    "\n",
    "- **`aisuite`**: OpenAI API í†µí•© ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "- **`google-generativeai`**: Google Gemini API ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "- **`requests`**: PubMed API í˜¸ì¶œì„ ìœ„í•œ HTTP ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "- **`python-dotenv`**: í™˜ê²½ ë³€ìˆ˜ ê´€ë¦¬ (.env íŒŒì¼)\n",
    "\n",
    "## ðŸ”‘ API í‚¤ ì„¤ì •\n",
    "\n",
    "`.env` íŒŒì¼ì— ë‹¤ìŒ API í‚¤ë¥¼ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤:\n",
    "```\n",
    "OPENAI_API_KEY=your_openai_key\n",
    "GOOGLE_API_KEY=your_google_key\n",
    "```\n",
    "\n",
    "## âš™ï¸ API ì œê³µìž ì„ íƒ\n",
    "\n",
    "ì•„ëž˜ ì½”ë“œì—ì„œ `API_PROVIDER` ë³€ìˆ˜ë¥¼ ìˆ˜ì •í•˜ì—¬ ì‚¬ìš©í•  ëª¨ë¸ì„ ì„ íƒí•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤:\n",
    "- `\"openai\"`: GPT-4o ì‚¬ìš©\n",
    "- `\"gemini\"`: Gemini-2.0-flash-exp ì‚¬ìš©\n",
    "\n",
    "**ì‹¤í–‰ í›„ í™•ì¸í•  ê²ƒ:**\n",
    "- âœ… ì‚¬ìš©í•  ëª¨ë¸ ì¶œë ¥\n",
    "- API í‚¤ê°€ ì˜¬ë°”ë¥´ê²Œ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì‚¬ìš©í•  ëª¨ë¸: gpt-4o (Provider: openai)\n",
      "âœ… OpenAI APIí‚¤ì™€ AISuiteë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤\n",
      "\n",
      "âœ… í™˜ê²½ ì„¤ì • ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Imports\n",
    "# =========================\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import inspect\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any, Callable\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import aisuite as ai\n",
    "import google.generativeai as genai\n",
    "from google.generativeai.types import FunctionDeclaration, Tool\n",
    "from google.generativeai import protos\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "# ===== ì‚¬ìš©í•  API ì œê³µìž ì„ íƒ =====\n",
    "# \"openai\" ë˜ëŠ” \"gemini\" ì¤‘ ì„ íƒ\n",
    "API_PROVIDER = \"openai\"  \n",
    "# ==================================\n",
    "\n",
    "# ì œê³µìžì— ë”°ë¼ ëª¨ë¸ ìžë™ ì„ íƒ\n",
    "if API_PROVIDER == \"openai\":\n",
    "    MODEL = \"gpt-4o\"\n",
    "elif API_PROVIDER == \"gemini\":\n",
    "    MODEL = \"gemini-2.0-flash-exp\"\n",
    "else:\n",
    "    raise ValueError(f\"ì§€ì›í•˜ì§€ ì•ŠëŠ” API_PROVIDER: {API_PROVIDER}\")\n",
    "\n",
    "print(f\"âœ… ì‚¬ìš©í•  ëª¨ë¸: {MODEL} (Provider: {API_PROVIDER})\")\n",
    "\n",
    "# API ì œê³µìžì— ë”°ë¼ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”\n",
    "if API_PROVIDER == \"openai\":\n",
    "    ai_client = ai.Client()\n",
    "    print(\"âœ… OpenAI APIí‚¤ì™€ AISuiteë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤\")\n",
    "elif API_PROVIDER == \"gemini\":\n",
    "    genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "    print(\"âœ… Google Gemini APIí‚¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤\")\n",
    "else:\n",
    "    ai_client = None\n",
    "    print(\"âš ï¸ No API client available\")\n",
    "\n",
    "print(\"\\nâœ… í™˜ê²½ ì„¤ì • ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2. UnifiedLLMClient í´ëž˜ìŠ¤\n",
    "\n",
    "## ðŸ”„ í†µí•© API í´ë¼ì´ì–¸íŠ¸\n",
    "\n",
    "ì´ í´ëž˜ìŠ¤ëŠ” OpenAIì™€ Gemini APIë¥¼ í•˜ë‚˜ì˜ ì¸í„°íŽ˜ì´ìŠ¤ë¡œ í†µí•©í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ì£¼ìš” ê¸°ëŠ¥:\n",
    "\n",
    "1. **í†µí•© ì¸í„°íŽ˜ì´ìŠ¤**: OpenAIì™€ Gemini ëª¨ë‘ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ í˜¸ì¶œ\n",
    "2. **ìžë™ ë³€í™˜**: Geminiì˜ ê²½ìš° Python í•¨ìˆ˜ë¥¼ Gemini Tool í˜•ì‹ìœ¼ë¡œ ìžë™ ë³€í™˜\n",
    "3. **Tool Calling ì§€ì›**: ë‘ API ëª¨ë‘ì—ì„œ í•¨ìˆ˜ í˜¸ì¶œ(Tool Calling) ê¸°ëŠ¥ ì‚¬ìš© ê°€ëŠ¥\n",
    "\n",
    "### ìž‘ë™ ë°©ì‹:\n",
    "\n",
    "**OpenAI ëª¨ë“œ:**\n",
    "- AISuiteë¥¼ í†µí•´ OpenAI API í˜¸ì¶œ\n",
    "- í‘œì¤€ OpenAI í˜•ì‹ì˜ ë©”ì‹œì§€ì™€ ë„êµ¬ ì‚¬ìš©\n",
    "\n",
    "**Gemini ëª¨ë“œ:**\n",
    "- Python í•¨ìˆ˜ë¥¼ Geminiì˜ FunctionDeclaration í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "- í•¨ìˆ˜ í˜¸ì¶œ ê²°ê³¼ë¥¼ Geminiì— ì „ë‹¬í•˜ì—¬ ëŒ€í™” ì§„í–‰\n",
    "- ìµœì¢… ê²°ê³¼ë¥¼ OpenAI í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜\n",
    "\n",
    "### ì‚¬ìš©ë²•:\n",
    "```python\n",
    "client.chat_completions_create(\n",
    "    messages=[{\"role\": \"user\", \"content\": \"...\"}],\n",
    "    tools=[í•¨ìˆ˜1, í•¨ìˆ˜2],  # ì„ íƒì‚¬í•­\n",
    "    max_turns=5  # Tool calling ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜\n",
    ")\n",
    "```\n",
    "\n",
    "**ì‹¤í–‰ í›„ í™•ì¸í•  ê²ƒ:**\n",
    "- âœ… UnifiedLLMClient ì´ˆê¸°í™” ì™„ë£Œ ë©”ì‹œì§€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… UnifiedLLMClient ì´ˆê¸°í™” ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# í†µí•© API ëž˜í¼ í´ëž˜ìŠ¤\n",
    "class UnifiedLLMClient:\n",
    "    \"\"\"OpenAIì™€ Gemini APIë¥¼ í†µí•©í•˜ì—¬ ì‚¬ìš©í•˜ëŠ” ëž˜í¼ í´ëž˜ìŠ¤\"\"\"\n",
    "\n",
    "    def __init__(self, provider, model, client=None):\n",
    "        self.provider = provider\n",
    "        self.model = model\n",
    "        self.ai_client = client\n",
    "\n",
    "    def _convert_tools_to_gemini(self, tools: List[Callable]) -> List[Tool]:\n",
    "        \"\"\"Python í•¨ìˆ˜ë¥¼ Gemini Tool í˜•ì‹ìœ¼ë¡œ ë³€í™˜\"\"\"\n",
    "        function_declarations = []\n",
    "\n",
    "        for tool in tools:\n",
    "            # Docstringì—ì„œ ì„¤ëª… ì¶”ì¶œ\n",
    "            description = tool.__doc__ or f\"Execute {tool.__name__}\"\n",
    "            description = description.strip()\n",
    "\n",
    "            # í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ì—ì„œ íŒŒë¼ë¯¸í„° ì •ë³´ ì¶”ì¶œ\n",
    "            sig = inspect.signature(tool)\n",
    "            parameters = {\"type\": \"object\", \"properties\": {}, \"required\": []}\n",
    "\n",
    "            for param_name, param in sig.parameters.items():\n",
    "                # íŒŒë¼ë¯¸í„° íƒ€ìž… ì¶”ë¡ \n",
    "                param_type = \"string\"  # ê¸°ë³¸ê°’\n",
    "                if param.annotation != inspect.Parameter.empty:\n",
    "                    if param.annotation == int:\n",
    "                        param_type = \"integer\"\n",
    "                    elif param.annotation == float:\n",
    "                        param_type = \"number\"\n",
    "                    elif param.annotation == bool:\n",
    "                        param_type = \"boolean\"\n",
    "\n",
    "                parameters[\"properties\"][param_name] = {\"type\": param_type}\n",
    "\n",
    "                # required íŒŒë¼ë¯¸í„° ì²´í¬\n",
    "                if param.default == inspect.Parameter.empty:\n",
    "                    parameters[\"required\"].append(param_name)\n",
    "\n",
    "            # í•¨ìˆ˜ ì„ ì–¸ ìƒì„±\n",
    "            func_decl = FunctionDeclaration(\n",
    "                name=tool.__name__,\n",
    "                description=description,\n",
    "                parameters=parameters\n",
    "            )\n",
    "            function_declarations.append(func_decl)\n",
    "\n",
    "        return [Tool(function_declarations=function_declarations)]\n",
    "\n",
    "    def chat_completions_create(self, messages, tools=None, max_turns=5, **kwargs):\n",
    "        \"\"\"í†µí•© chat completion ì¸í„°íŽ˜ì´ìŠ¤\"\"\"\n",
    "\n",
    "        if self.provider == \"openai\":\n",
    "            # AISuite (OpenAI) ì‚¬ìš©\n",
    "            call_kwargs = {\n",
    "                \"model\": f\"openai:{self.model}\",\n",
    "                \"messages\": messages,\n",
    "            }\n",
    "            if tools:\n",
    "                call_kwargs[\"tools\"] = tools\n",
    "            call_kwargs.update(kwargs)\n",
    "            \n",
    "            response = self.ai_client.chat.completions.create(**call_kwargs)\n",
    "            return response\n",
    "\n",
    "        elif self.provider == \"gemini\":\n",
    "            # Google Generative AI ì‚¬ìš©\n",
    "            gemini_model = genai.GenerativeModel(\n",
    "                model_name=self.model,\n",
    "                tools=self._convert_tools_to_gemini(tools) if tools else None\n",
    "            )\n",
    "\n",
    "            # ë©”ì‹œì§€ë¥¼ Gemini í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "            prompt = messages[-1][\"content\"] if isinstance(messages, list) else str(messages)\n",
    "\n",
    "            # Tool í•¨ìˆ˜ ë§¤í•‘\n",
    "            tool_map = {tool.__name__: tool for tool in tools} if tools else {}\n",
    "\n",
    "            # ëŒ€í™” ì‹œìž‘\n",
    "            chat = gemini_model.start_chat()\n",
    "\n",
    "            # ì²« ë©”ì‹œì§€ ì „ì†¡\n",
    "            response = chat.send_message(prompt)\n",
    "\n",
    "            # í•¨ìˆ˜ í˜¸ì¶œ ë£¨í”„ (max_turns ì œí•œ)\n",
    "            for turn in range(max_turns):\n",
    "                function_called = False\n",
    "\n",
    "                for part in response.parts:\n",
    "                    if part.function_call:\n",
    "                        function_name = part.function_call.name\n",
    "                        function_args = dict(part.function_call.args)\n",
    "\n",
    "                        # í•¨ìˆ˜ ì‹¤í–‰ (íŒŒë¼ë¯¸í„° í¬í•¨)\n",
    "                        function_result = tool_map[function_name](**function_args)\n",
    "\n",
    "                        # ê²°ê³¼ë¥¼ ëª¨ë¸ì— ì „ë‹¬\n",
    "                        function_response_part = protos.Part(\n",
    "                            function_response=protos.FunctionResponse(\n",
    "                                name=function_name,\n",
    "                                response={\"result\": str(function_result)}\n",
    "                            )\n",
    "                        )\n",
    "\n",
    "                        response = chat.send_message(function_response_part)\n",
    "                        function_called = True\n",
    "                        break\n",
    "\n",
    "                if not function_called:\n",
    "                    break\n",
    "\n",
    "            # AISuite í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ ë³€í™˜\n",
    "            class MockChoice:\n",
    "                def __init__(self, text):\n",
    "                    self.message = type('obj', (object,), {'content': text})()\n",
    "\n",
    "            class MockResponse:\n",
    "                def __init__(self, text):\n",
    "                    self.choices = [MockChoice(text)]\n",
    "\n",
    "            return MockResponse(response.text)\n",
    "\n",
    "# í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”\n",
    "client = UnifiedLLMClient(API_PROVIDER, MODEL, ai_client if API_PROVIDER == \"openai\" else None)\n",
    "\n",
    "print(\"âœ… UnifiedLLMClient ì´ˆê¸°í™” ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 3. PubMed ê²€ìƒ‰ ë„êµ¬\n",
    "\n",
    "## ðŸ”¬ PubMed API ì—°ë™\n",
    "\n",
    "ì´ í•¨ìˆ˜ëŠ” PubMed E-utilities APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜í•™/ì‹¬ë¦¬í•™ ë…¼ë¬¸ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ìž‘ë™ ê³¼ì •:\n",
    "\n",
    "1. **ê²€ìƒ‰ ë‹¨ê³„** (`esearch.fcgi`):\n",
    "   - ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ PubMedì— ì „ì†¡\n",
    "   - PMID(PubMed ID) ëª©ë¡ì„ ë°›ì•„ì˜´\n",
    "   - ì „ì²´ ê²°ê³¼ ìˆ˜ì™€ ë°˜í™˜ëœ ê²°ê³¼ ìˆ˜ í™•ì¸\n",
    "\n",
    "2. **ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°** (`esummary.fcgi`):\n",
    "   - PMID ëª©ë¡ì„ ì‚¬ìš©í•˜ì—¬ ê° ë…¼ë¬¸ì˜ ìƒì„¸ ì •ë³´ ìš”ì²­\n",
    "   - ì œëª©, ì €ìž, ì¶œíŒì¼, ì €ë„, DOI ë“± ì¶”ì¶œ\n",
    "\n",
    "3. **ë°ì´í„° ì •ë¦¬**:\n",
    "   - ê° ë…¼ë¬¸ì˜ ì •ë³´ë¥¼ êµ¬ì¡°í™”ëœ JSON í˜•íƒœë¡œ ì •ë¦¬\n",
    "   - APA í˜•ì‹ ìƒì„±ì„ ìœ„í•œ ì •ë³´ í¬í•¨ (ì €ìžëª…, ë…„ë„, ì €ë„ ë“±)\n",
    "\n",
    "### ë°˜í™˜ ë°ì´í„° êµ¬ì¡°:\n",
    "```json\n",
    "{\n",
    "  \"query\": \"ê²€ìƒ‰ ì¿¼ë¦¬\",\n",
    "  \"total_count\": \"ì „ì²´ ê²°ê³¼ ìˆ˜\",\n",
    "  \"returned_count\": \"ë°˜í™˜ëœ ê²°ê³¼ ìˆ˜\",\n",
    "  \"papers\": [\n",
    "    {\n",
    "      \"pmid\": \"ë…¼ë¬¸ ID\",\n",
    "      \"title\": \"ë…¼ë¬¸ ì œëª©\",\n",
    "      \"authors\": [\"ì €ìž1\", \"ì €ìž2\", ...],\n",
    "      \"first_author\": \"ì²« ë²ˆì§¸ ì €ìž\",\n",
    "      \"year\": \"ì¶œíŒ ë…„ë„\",\n",
    "      \"journal\": \"ì €ë„ëª…\",\n",
    "      \"doi\": \"DOI\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "### ì‚¬ìš© ì˜ˆì‹œ:\n",
    "```python\n",
    "result = pubmed_search_tool(\n",
    "    query=\"memory AND fMRI\",\n",
    "    max_results=10\n",
    ")\n",
    "```\n",
    "\n",
    "**ì‹¤í–‰ í›„ í™•ì¸í•  ê²ƒ:**\n",
    "- í…ŒìŠ¤íŠ¸ ê²€ìƒ‰ì´ ì •ìƒì ìœ¼ë¡œ ì‹¤í–‰ë˜ëŠ”ì§€ í™•ì¸\n",
    "- ë°˜í™˜ëœ ë…¼ë¬¸ ì •ë³´ê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª PubMed ê²€ìƒ‰ ë„êµ¬ í…ŒìŠ¤íŠ¸\n",
      "ê²€ìƒ‰ ì¿¼ë¦¬: 'large language model AND memory'\n",
      "ìµœëŒ€ ê²°ê³¼: 3ê°œ\n",
      "\n",
      "âœ… ê²€ìƒ‰ ì™„ë£Œ: 3ê°œ ë…¼ë¬¸ ë°œê²¬\n",
      "\n",
      "ì²« ë²ˆì§¸ ë…¼ë¬¸ ì˜ˆì‹œ:\n",
      "  ì œëª©: Empowering biomedical discovery with AI agents....\n",
      "  ì €ìž: Gao S, Fang A, Huang Y, Giunchiglia V, Noori A, Schwarz JR, Ektefaie Y, Kondic J, Zitnik M\n",
      "  ë…„ë„: 2024\n",
      "  ì œëª©: Large language models' knowledge of children's memory and suggestibility: Evaluating model predictions of prior experimental results....\n",
      "  ì €ìž: Santtila P, Sun Y, Kask K, JÃ¤rvilehto L, Xiu J\n",
      "  ë…„ë„: 2025\n"
     ]
    }
   ],
   "source": [
    "def pubmed_search_tool(query: str, max_results: int = 10) -> str:\n",
    "    \"\"\"\n",
    "    PubMedì—ì„œ ë…¼ë¬¸ì„ ê²€ìƒ‰í•˜ëŠ” ë„êµ¬\n",
    "    \n",
    "    Args:\n",
    "        query (str): ê²€ìƒ‰ ì¿¼ë¦¬\n",
    "        max_results (int): ìµœëŒ€ ê²°ê³¼ ìˆ˜\n",
    "    \n",
    "    Returns:\n",
    "        str: ê²€ìƒ‰ ê²°ê³¼ JSON ë¬¸ìžì—´\n",
    "    \"\"\"\n",
    "    base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/\"\n",
    "    \n",
    "    # 1. ê²€ìƒ‰í•˜ì—¬ PMID ëª©ë¡ ê°€ì ¸ì˜¤ê¸°\n",
    "    search_url = f\"{base_url}esearch.fcgi\"\n",
    "    search_params = {\n",
    "        \"db\": \"pubmed\",\n",
    "        \"term\": query,\n",
    "        \"retmax\": max_results,\n",
    "        \"retmode\": \"json\",\n",
    "        \"sort\": \"relevance\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        search_response = requests.get(search_url, params=search_params)\n",
    "        search_data = search_response.json()\n",
    "        \n",
    "        if \"esearchresult\" not in search_data or \"idlist\" not in search_data[\"esearchresult\"]:\n",
    "            return json.dumps({\"error\": \"No results found\", \"count\": 0})\n",
    "        \n",
    "        pmids = search_data[\"esearchresult\"][\"idlist\"]\n",
    "        total_count = search_data[\"esearchresult\"][\"count\"]\n",
    "        \n",
    "        if not pmids:\n",
    "            return json.dumps({\"error\": \"No results found\", \"count\": 0})\n",
    "        \n",
    "        # 2. PMIDë¡œ ë…¼ë¬¸ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°\n",
    "        summary_url = f\"{base_url}esummary.fcgi\"\n",
    "        summary_params = {\n",
    "            \"db\": \"pubmed\",\n",
    "            \"id\": \",\".join(pmids),\n",
    "            \"retmode\": \"json\"\n",
    "        }\n",
    "        \n",
    "        summary_response = requests.get(summary_url, params=summary_params)\n",
    "        summary_data = summary_response.json()\n",
    "        \n",
    "        # ê²°ê³¼ ì •ë¦¬\n",
    "        papers = []\n",
    "        for pmid in pmids:\n",
    "            if pmid in summary_data[\"result\"]:\n",
    "                paper_data = summary_data[\"result\"][pmid]\n",
    "                \n",
    "                # ì €ìž ì •ë³´ ì¶”ì¶œ\n",
    "                authors = []\n",
    "                if \"authors\" in paper_data:\n",
    "                    authors = [author[\"name\"] for author in paper_data[\"authors\"]]\n",
    "                \n",
    "                # ì²« ë²ˆì§¸ ì €ìž ì¶”ì¶œ (APA í˜•ì‹ìš©)\n",
    "                first_author = authors[0] if authors else \"Unknown\"\n",
    "                \n",
    "                papers.append({\n",
    "                    \"pmid\": pmid,\n",
    "                    \"title\": paper_data.get(\"title\", \"No title\"),\n",
    "                    \"authors\": authors,\n",
    "                    \"first_author\": first_author,\n",
    "                    \"pubdate\": paper_data.get(\"pubdate\", \"Unknown\"),\n",
    "                    \"year\": paper_data.get(\"pubdate\", \"Unknown\").split()[0],\n",
    "                    \"journal\": paper_data.get(\"fulljournalname\", \"Unknown\"),\n",
    "                    \"volume\": paper_data.get(\"volume\", \"\"),\n",
    "                    \"issue\": paper_data.get(\"issue\", \"\"),\n",
    "                    \"pages\": paper_data.get(\"pages\", \"\"),\n",
    "                    \"doi\": paper_data.get(\"elocationid\", \"\")\n",
    "                })\n",
    "        \n",
    "        result = {\n",
    "            \"query\": query,\n",
    "            \"total_count\": total_count,\n",
    "            \"returned_count\": len(papers),\n",
    "            \"papers\": papers\n",
    "        }\n",
    "        \n",
    "        return json.dumps(result, indent=2, ensure_ascii=False)\n",
    "        \n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": str(e)})\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "print(\"ðŸ§ª PubMed ê²€ìƒ‰ ë„êµ¬ í…ŒìŠ¤íŠ¸\")\n",
    "print(\"ê²€ìƒ‰ ì¿¼ë¦¬: 'large language model AND memory'\")\n",
    "print(\"ìµœëŒ€ ê²°ê³¼: 3ê°œ\\n\")\n",
    "\n",
    "test_result = pubmed_search_tool(\"large language model AND memory\", max_results=3)\n",
    "test_data = json.loads(test_result)\n",
    "\n",
    "print(f\"âœ… ê²€ìƒ‰ ì™„ë£Œ: {test_data.get('returned_count', 0)}ê°œ ë…¼ë¬¸ ë°œê²¬\")\n",
    "if 'papers' in test_data and test_data['papers']:\n",
    "    print(f\"\\nì²« ë²ˆì§¸ ë…¼ë¬¸ ì˜ˆì‹œ:\")\n",
    "    first_paper = test_data['papers'][0]\n",
    "    print(f\"  ì œëª©: {first_paper['title'][:800]}...\")\n",
    "    print(f\"  ì €ìž: {', '.join(first_paper['authors'][:100])}\")\n",
    "    print(f\"  ë…„ë„: {first_paper['year']}\")\n",
    "    second_paper = test_data['papers'][1]\n",
    "    print(f\"  ì œëª©: {second_paper['title'][:800]}...\")\n",
    "    print(f\"  ì €ìž: {', '.join(second_paper['authors'][:100])}\")\n",
    "    print(f\"  ë…„ë„: {second_paper['year']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 4. Agent 0: í† í”½ ì •ì˜ ì—ì´ì „íŠ¸\n",
    "\n",
    "## ðŸ“‹ ì—°êµ¬ ì£¼ì œ êµ¬ì¡°í™”\n",
    "\n",
    "ì´ ì—ì´ì „íŠ¸ëŠ” ì‚¬ìš©ìžê°€ ìžìœ ë¡­ê²Œ ìž…ë ¥í•œ ì—°êµ¬ ì£¼ì œë¥¼ êµ¬ì¡°í™”ëœ ì •ë³´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ìž…ë ¥:\n",
    "- ìžìœ ë¡œìš´ í˜•íƒœì˜ ì—°êµ¬ ì£¼ì œ ì„¤ëª… (ì˜ˆ: \"LLMì„ ì‚¬ìš©í•´ì„œ ì¸ê°„ì˜ ê¸°ì–µì„ ì˜ˆì¸¡í•˜ê³  ì‹¶ì–´ìš”\")\n",
    "\n",
    "### ì¶œë ¥:\n",
    "1. **Main Topic**: í•µì‹¬ ì—°êµ¬ ì£¼ì œ (1-2 ë¬¸ìž¥)\n",
    "2. **Research Field**: í•™ë¬¸ ë¶„ì•¼ (ì˜ˆ: Neuroscience, AI, Psychology)\n",
    "3. **Specific Focus**: ì„¸ë¶€ ì—°êµ¬ ì˜ì—­\n",
    "4. **Methods**: ì—°êµ¬ ë°©ë²•ë¡  (ì˜ˆ: fMRI, LLM, behavioral)\n",
    "5. **Keywords**: PubMed ê²€ìƒ‰ìš© í‚¤ì›Œë“œ 5-7ê°œ\n",
    "6. **PubMed Query**: ì œì•ˆëœ ê²€ìƒ‰ ì¿¼ë¦¬ 3-5ê°œ\n",
    "\n",
    "### ìž‘ë™ ë°©ì‹:\n",
    "1. ì‚¬ìš©ìžì˜ ìžìœ ë¡œìš´ ì„¤ëª…ì„ ë°›ìŒ\n",
    "2. LLMì´ êµ¬ì¡°í™”ëœ ì •ë³´ë¡œ ë³€í™˜\n",
    "3. PubMed ê²€ìƒ‰ì— ì í•©í•œ ì¿¼ë¦¬ ìžë™ ìƒì„±\n",
    "\n",
    "### ì™œ í•„ìš”í•œê°€?\n",
    "- íš¨ê³¼ì ì¸ ë¬¸í—Œ ê²€ìƒ‰ì„ ìœ„í•´ì„œëŠ” ëª…í™•í•œ í‚¤ì›Œë“œì™€ ì¿¼ë¦¬ê°€ í•„ìš”\n",
    "- ì—°êµ¬ ì£¼ì œë¥¼ êµ¬ì¡°í™”í•˜ë©´ í›„ì† ì—ì´ì „íŠ¸ë“¤ì´ ë” ì •í™•í•˜ê²Œ ìž‘ë™\n",
    "- ì‚¬ìš©ìžê°€ ìƒê°í•˜ì§€ ëª»í•œ ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ì œì•ˆë°›ì„ ìˆ˜ ìžˆìŒ\n",
    "\n",
    "**ì‹¤í–‰ ë°©ë²•:**\n",
    "1. ì•„ëž˜ ì…€ì˜ `user_input` ë³€ìˆ˜ì— ì—°êµ¬ ì£¼ì œë¥¼ ìž…ë ¥í•˜ì„¸ìš”\n",
    "2. ë˜ëŠ” `None`ìœ¼ë¡œ ë‘ë©´ ì‹¤í–‰ ì‹œ ìž…ë ¥ í”„ë¡¬í”„íŠ¸ê°€ ë‚˜íƒ€ë‚©ë‹ˆë‹¤\n",
    "3. ì…€ì„ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… í† í”½ ì •ì˜ ì—ì´ì „íŠ¸ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "def topic_definition_agent(user_input: str = None) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    í† í”½ ì •ì˜ ì—ì´ì „íŠ¸: ì‚¬ìš©ìžë¡œë¶€í„° ì—°êµ¬ ì£¼ì œ ì •ë³´ë¥¼ ìˆ˜ì§‘\n",
    "    \n",
    "    Args:\n",
    "        user_input (str): ì‚¬ìš©ìžê°€ ì œê³µí•œ ì´ˆê¸° í† í”½ ì„¤ëª…\n",
    "    \n",
    "    Returns:\n",
    "        dict: êµ¬ì¡°í™”ëœ í† í”½ ì •ë³´\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ðŸ“‹ í† í”½ ì •ì˜ ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘...\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    if user_input is None:\n",
    "        print(\"ì—°êµ¬ ì£¼ì œì— ëŒ€í•´ ìžìœ ë¡­ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”:\")\n",
    "        user_input = input(\"> \")\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "You are a research planning assistant.\n",
    "\n",
    "User's research topic description:\n",
    "{user_input}\n",
    "\n",
    "Your task:\n",
    "Based on the user's description, extract and structure the following information:\n",
    "\n",
    "1. **Main Topic**: The core research topic (1-2 sentences)\n",
    "2. **Research Field**: Academic field (e.g., Neuroscience, Psychology, AI, etc.)\n",
    "3. **Specific Focus**: More specific area within the field\n",
    "4. **Methods**: Research methods or approaches (e.g., fMRI, behavioral experiments, computational modeling, LLM)\n",
    "5. **Keywords**: 5-7 keywords for PubMed search\n",
    "6. **PubMed Query**: Suggest 3-5 different PubMed search queries using AND/OR operators\n",
    "\n",
    "Please provide the information in a clear, structured format.\n",
    "Be specific and concrete to help with literature search.\n",
    "\"\"\"\n",
    "    \n",
    "    response = client.chat_completions_create(\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        tools=[],\n",
    "        max_turns=1\n",
    "    )\n",
    "    \n",
    "    result = response.choices[0].message.content\n",
    "    \n",
    "    print(\"\\nâœ… í† í”½ ì •ì˜ ì™„ë£Œ\")\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ðŸ“Œ ì •ì˜ëœ í† í”½ ì •ë³´\")\n",
    "    print(\"=\"*60)\n",
    "    print(result)\n",
    "    \n",
    "    return {\n",
    "        \"user_input\": user_input,\n",
    "        \"structured_topic\": result\n",
    "    }\n",
    "\n",
    "print(\"âœ… í† í”½ ì •ì˜ ì—ì´ì „íŠ¸ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Agent 0 ì‹¤í–‰í•˜ê¸°\n",
    "\n",
    "ì•„ëž˜ ì…€ì„ ì‹¤í–‰í•˜ì—¬ í† í”½ ì •ì˜ ì—ì´ì „íŠ¸ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.\n",
    "\n",
    "**ìž…ë ¥ ë°©ë²•:**\n",
    "- `user_topic` ë³€ìˆ˜ì— ì§ì ‘ ì—°êµ¬ ì£¼ì œë¥¼ ìž…ë ¥í•˜ê±°ë‚˜\n",
    "- `None`ìœ¼ë¡œ ë‘ê³  ì‹¤í–‰í•˜ë©´ ëŒ€í™”í˜•ìœ¼ë¡œ ìž…ë ¥í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤\n",
    "\n",
    "**ì˜ˆì‹œ ìž…ë ¥:**\n",
    "- \"LLMì„ í™œìš©í•œ ì¸ê°„ ê¸°ì–µ ì˜ˆì¸¡ ë° í‰ê°€ ë„êµ¬ ê°œë°œ\"\n",
    "- \"fMRIë¥¼ ì‚¬ìš©í•œ ìš°ìš¸ì¦ í™˜ìžì˜ ë‡Œ í™œë™ íŒ¨í„´ ì—°êµ¬\"\n",
    "- \"ìžì—°ìŠ¤ëŸ¬ìš´ í™˜ê²½ì—ì„œì˜ ì¸ê°„ ê¸°ì–µ íšŒìƒ ì—°êµ¬\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ“‹ í† í”½ ì •ì˜ ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘...\n",
      "============================================================\n",
      "\n",
      "\n",
      "âœ… í† í”½ ì •ì˜ ì™„ë£Œ\n",
      "\n",
      "============================================================\n",
      "ðŸ“Œ ì •ì˜ëœ í† í”½ ì •ë³´\n",
      "============================================================\n",
      "Certainly! Here is the structured information based on the user's research topic description:\n",
      "\n",
      "1. **Main Topic**: \n",
      "   Investigating the causal relationship between supra-modal memory retention and activity in the Superior Parietal Cortex (SPC) by applying Transcranial Magnetic Stimulation (TMS) and measuring changes in working memory performance in the presence or absence of distractors.\n",
      "\n",
      "2. **Research Field**: \n",
      "   Neuroscience\n",
      "\n",
      "3. **Specific Focus**: \n",
      "   Cognitive Neuroscience, with an emphasis on working memory and brain stimulation techniques.\n",
      "\n",
      "4. **Methods**: \n",
      "   - Transcranial Magnetic Stimulation (TMS)\n",
      "   - Behavioral experiments measuring working memory performance\n",
      "\n",
      "5. **Keywords**: \n",
      "   - Transcranial Magnetic Stimulation\n",
      "   - Superior Parietal Cortex\n",
      "   - Working Memory\n",
      "   - Distractors\n",
      "   - Supra-modal Memory\n",
      "   - Cognitive Neuroscience\n",
      "   - Brain Stimulation\n",
      "\n",
      "6. **PubMed Query**: \n",
      "   1. \"Transcranial Magnetic Stimulation AND Superior Parietal Cortex AND Working Memory AND Distractors\"\n",
      "   2. \"Working Memory AND Supra-modal Memory AND Superior Parietal Cortex\"\n",
      "   3. \"Transcranial Magnetic Stimulation AND Cognitive Neuroscience AND Distractors AND Brain Stimulation\"\n",
      "   4. \"Brain Stimulation AND Superior Parietal Cortex AND Working Memory\"\n",
      "   5. \"TMS AND Supra-modal Memory AND Superior Parietal Cortex AND Distractors\"\n",
      "\n",
      "This structured information is designed to help facilitate a comprehensive literature search in PubMed and related academic databases.\n",
      "\n",
      "=================================================================\n",
      "ðŸ’¾ Agent 0 ê²°ê³¼ ì €ìž¥ ì™„ë£Œ\n",
      "=================================================================\n",
      "íŒŒì¼ëª…: agent0_topic_definition_20251104_013335.txt\n"
     ]
    }
   ],
   "source": [
    "# ì—¬ê¸°ì— ì—°êµ¬ ì£¼ì œë¥¼ ìž…ë ¥í•˜ì„¸ìš”\n",
    "# Noneìœ¼ë¡œ ë‘ë©´ ì‹¤í–‰ ì‹œ ìž…ë ¥ í”„ë¡¬í”„íŠ¸ê°€ ë‚˜íƒ€ë‚©ë‹ˆë‹¤\n",
    "user_topic = \"TMSë¥¼ SPC(Superior parietal cortex)ì— ì ìš©í•˜ì—¬ distractorì˜ ìœ ë¬´ì— ë”°ë¥¸ working memory ìˆ˜í–‰ ë³€í™”ë¥¼ ì¸¡ì •í•¨ìœ¼ë¡œì¨ supra-modal memory retensionê³¼ SPC í™œë™ì˜ ì¸ê³¼ê´€ê³„ ê·œëª…\"\n",
    "\n",
    "# Agent 0 ì‹¤í–‰\n",
    "topic_info = topic_definition_agent(user_topic)\n",
    "\n",
    "# íƒ€ìž„ìŠ¤íƒ¬í”„ ìƒì„±\n",
    "timestamp_agent0 = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ìž¥\n",
    "topic_filename = f\"agent0_topic_definition_{timestamp_agent0}.txt\"\n",
    "with open(topic_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(f\"User Input:\\n{topic_info['user_input']}\\n\\n\")\n",
    "    f.write(\"=\"*65 + \"\\n\")\n",
    "    f.write(\"Structured Topic Information:\\n\")\n",
    "    f.write(\"=\"*65 + \"\\n\\n\")\n",
    "    f.write(topic_info['structured_topic'])\n",
    "\n",
    "print(\"\\n\" + \"=\"*65)\n",
    "print(\"ðŸ’¾ Agent 0 ê²°ê³¼ ì €ìž¥ ì™„ë£Œ\")\n",
    "print(\"=\"*65)\n",
    "print(f\"íŒŒì¼ëª…: {topic_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 5. Agent 1: PubMed ê²€ìƒ‰ ë° APA í˜•ì‹ ì •ë¦¬ ì—ì´ì „íŠ¸\n",
    "\n",
    "## ðŸ” ë…¼ë¬¸ ê²€ìƒ‰ ë° ë ˆí¼ëŸ°ìŠ¤ ìƒì„±\n",
    "\n",
    "ì´ ì—ì´ì „íŠ¸ëŠ” PubMedì—ì„œ ë…¼ë¬¸ì„ ê²€ìƒ‰í•˜ê³ , APA 7th edition í˜•ì‹ìœ¼ë¡œ ë ˆí¼ëŸ°ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ì£¼ìš” ê¸°ëŠ¥:\n",
    "\n",
    "#### 1. **ê³ ê¸‰ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±**\n",
    "- ì¸ì§€ ì‹ ê²½ ì „ë¬¸ê°€ íŽ˜ë¥´ì†Œë‚˜ë¡œ 3-5ê°œ ìµœì í™”ëœ ì¿¼ë¦¬ ìƒì„±\n",
    "- PubMed ê³ ê¸‰ ë¬¸ë²• ì‚¬ìš© (AND/OR, MeSH terms, ë™ì˜ì–´)\n",
    "- ì—°êµ¬ ë°©ë²• ë° ëŒ€ìƒ í¬í•¨\n",
    "\n",
    "#### 2. **ëŒ€í™”í˜• ì¿¼ë¦¬ ì„ íƒ**\n",
    "ì‚¬ìš©ìžëŠ” ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤:\n",
    "- **[1-N]**: ì œì•ˆëœ ì¿¼ë¦¬ ì¤‘ í•˜ë‚˜ ì„ íƒ\n",
    "- **[Enter]**: ì²« ë²ˆì§¸ ì¿¼ë¦¬ ì‚¬ìš© (ê¸°ë³¸ê°’)\n",
    "- **[all]**: ëª¨ë“  ì¿¼ë¦¬ë¥¼ ORë¡œ ì—°ê²°í•˜ì—¬ ê²€ìƒ‰\n",
    "- **[custom]**: ì§ì ‘ ì¿¼ë¦¬ ìž…ë ¥\n",
    "\n",
    "#### 3. **PubMed ê²€ìƒ‰ ì‹¤í–‰**\n",
    "- ì„ íƒëœ ì¿¼ë¦¬ë¡œ PubMed ê²€ìƒ‰\n",
    "- ë…¼ë¬¸ ì œëª©, ì €ìž, ë…„ë„, ì €ë„, DOI ë“± ìˆ˜ì§‘\n",
    "\n",
    "#### 4. **APA 7th í˜•ì‹ ë³€í™˜**\n",
    "- ê²€ìƒ‰ëœ ë…¼ë¬¸ì„ APA 7th edition í˜•ì‹ìœ¼ë¡œ ìžë™ ë³€í™˜\n",
    "- `01_referencing.py`ì˜ ê·œì¹™ ì ìš©\n",
    "- ë²ˆí˜¸ê°€ ë§¤ê²¨ì§„ ë ˆí¼ëŸ°ìŠ¤ ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "- ê° ë…¼ë¬¸ì— APA í˜•ì‹ ìžë™ ë§¤í•‘\n",
    "\n",
    "### APA 7th Edition í˜•ì‹ ì˜ˆì‹œ:\n",
    "```\n",
    "1. Smith, J. A., & Johnson, M. B. (2023). Memory prediction using large language models.\n",
    "   Nature Neuroscience, 26(4), 123-135. https://doi.org/10.1038/xxx\n",
    "\n",
    "2. Lee, K. (2022). Computational approaches to human memory.\n",
    "   Psychological Review, 129(2), 456-478. https://doi.org/10.1037/xxx\n",
    "```\n",
    "\n",
    "### ì¶œë ¥:\n",
    "- **ê²€ìƒ‰ ê²°ê³¼ ë°ì´í„°**: ë…¼ë¬¸ ìƒì„¸ ì •ë³´ (JSON)\n",
    "- **APA ë ˆí¼ëŸ°ìŠ¤**: ë²ˆí˜¸ê°€ ë§¤ê²¨ì§„ APA í˜•ì‹ ë ˆí¼ëŸ°ìŠ¤\n",
    "- **ì¸ìš© ì •ë³´**: Introduction ìž‘ì„±ì— ì‚¬ìš©í•  (ì €ìž, ë…„ë„) ì •ë³´\n",
    "- **ë§¤í•‘ëœ APA**: ê° ë…¼ë¬¸ ê°ì²´ì— `apa_formatted` í•„ë“œ í¬í•¨\n",
    "\n",
    "**ì‹¤í–‰ ë°©ë²•:**\n",
    "1. Agent 0ì´ ë¨¼ì € ì‹¤í–‰ë˜ì–´ ìžˆì–´ì•¼ í•©ë‹ˆë‹¤\n",
    "2. `max_papers` ë³€ìˆ˜ë¡œ ê²€ìƒ‰í•  ë…¼ë¬¸ ìˆ˜ë¥¼ ì¡°ì •í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤\n",
    "3. `interactive=True` (ê¸°ë³¸ê°’) ë˜ëŠ” `False`ë¡œ ëª¨ë“œ ì„ íƒ\n",
    "4. ì‹¤í–‰í•˜ë©´ ìµœì í™”ëœ ê²€ìƒ‰ ì¿¼ë¦¬ê°€ ì œì•ˆë˜ê³ , ì„ íƒí•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… literature_search_agent Ready!\n"
     ]
    }
   ],
   "source": [
    "def format_papers_for_prompt(papers: List[Dict[str, Any]]) -> str:\n",
    "    \"\"\"\n",
    "    PubMed ê²€ìƒ‰ ê²°ê³¼ë¥¼ LLMì´ ì½ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ë³€í™˜\n",
    "    \n",
    "    Args:\n",
    "        papers: ë…¼ë¬¸ ì •ë³´ ë¦¬ìŠ¤íŠ¸\n",
    "    \n",
    "    Returns:\n",
    "        str: í¬ë§·ëœ ë…¼ë¬¸ ì •ë³´ ë¬¸ìžì—´\n",
    "    \"\"\"\n",
    "    formatted = []\n",
    "    for p in papers:\n",
    "        formatted.append(\n",
    "            f\"Title: {p.get('title', 'N/A')}\\n\"\n",
    "            f\"Authors: {', '.join(p.get('authors', [])) if p.get('authors') else 'N/A'}\\n\"\n",
    "            f\"Year: {p.get('year', 'N/A')}\\n\"\n",
    "            f\"Journal: {p.get('journal', 'N/A')}\\n\"\n",
    "            f\"Volume: {p.get('volume', 'N/A')}, Issue: {p.get('issue', 'N/A')}, Pages: {p.get('pages', 'N/A')}\\n\"\n",
    "            f\"DOI: {p.get('doi', 'N/A')}\\n\"\n",
    "            \"-----\"\n",
    "        )\n",
    "    return \"\\n\".join(formatted)\n",
    "\n",
    "\n",
    "def literature_search_agent(\n",
    "    topic_info: Dict[str, Any],\n",
    "    max_papers: int = 20,\n",
    "    search_queries: List[str] = None,\n",
    "    interactive: bool = False,\n",
    "    year_range: str = None\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    ë¬¸í—Œ ê²€ìƒ‰ + APA ì„œì§€ ì •ë¦¬ ìžë™í™” ì—ì´ì „íŠ¸ (v2)\n",
    "    \n",
    "    Args:\n",
    "        topic_info (dict): í† í”½ ì •ì˜ ê²°ê³¼\n",
    "        max_papers (int): ê²€ìƒ‰í•  ìµœëŒ€ ë…¼ë¬¸ ìˆ˜\n",
    "        search_queries (list): ì‚¬ìš©ìž ì •ì˜ ê²€ìƒ‰ ì¿¼ë¦¬ (ì„ íƒ)\n",
    "        interactive (bool): ëŒ€í™”í˜• ëª¨ë“œ (ê¸°ë³¸ê°’: True)\n",
    "    \n",
    "    Returns:\n",
    "        dict: ê²€ìƒ‰ ê²°ê³¼ ë° APA í˜•ì‹ ë ˆí¼ëŸ°ìŠ¤\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*65)\n",
    "    print(\"ðŸ“š  Literature Search Agent v2 â€” PubMed & APA Formatter\")\n",
    "    print(\"=\"*65 + \"\\n\")\n",
    "    \n",
    "    # 1ï¸âƒ£ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±\n",
    "    if search_queries is None:\n",
    "        print(\"ðŸ¤” Generating optimized PubMed queries...\")\n",
    "        query_prompt = f\"\"\"\n",
    "You are a cognitive neuroscience specialist skilled in PubMed query design.\n",
    "\n",
    "Based on the topic below, generate 3â€“5 optimized PubMed search queries.\n",
    "\n",
    "Topic:\n",
    "{topic_info['structured_topic']}\n",
    "\n",
    "Guidelines:\n",
    "- Use AND/OR operators and MeSH terms where relevant.\n",
    "- Combine key concepts logically.\n",
    "- Include common synonyms using OR (e.g., \"working memory\" OR \"WM\").\n",
    "- Optionally limit by method or population (e.g., fMRI, human).\n",
    "- Keep each query under 300 characters.\n",
    "- Return only the queries, one per line, with no explanations.\n",
    "\"\"\"\n",
    "        query_response = client.chat_completions_create(\n",
    "            messages=[{\"role\": \"user\", \"content\": query_prompt}],\n",
    "            tools=[],\n",
    "            max_turns=1\n",
    "        )\n",
    "        query_text = query_response.choices[0].message.content.strip()\n",
    "        search_queries = [q.strip() for q in query_text.split(\"\\n\") if q.strip()]\n",
    "\n",
    "    print(\"\\nðŸ“Š Suggested PubMed Queries:\")\n",
    "    for i, q in enumerate(search_queries, 1):\n",
    "        print(f\"  {i}. {q}\")\n",
    "\n",
    "    # 2ï¸âƒ£ ì‚¬ìš©ìž ìž…ë ¥ (interactive ëª¨ë“œ)\n",
    "    if interactive:\n",
    "        print(\"\\nâœï¸  Select or modify a query:\")\n",
    "        print(\"   [1â€“N] â†’ choose one query\")\n",
    "        print(\"   [custom] â†’ enter manually\")\n",
    "        print(\"   [all] â†’ combine all with OR\")\n",
    "        print(\"   [Enter] â†’ default: first query\\n\")\n",
    "        user_choice = input(\"> \").strip()\n",
    "    else:\n",
    "        user_choice = \"all\"\n",
    "\n",
    "    if user_choice == \"\":\n",
    "        selected_query = search_queries[0]\n",
    "    elif user_choice.lower() == \"all\":\n",
    "        selected_query = \" OR \".join([f\"({q})\" for q in search_queries])\n",
    "    elif user_choice.lower() == \"custom\":\n",
    "        selected_query = input(\"\\nEnter custom query:\\n> \").strip()\n",
    "    elif user_choice.isdigit() and 1 <= int(user_choice) <= len(search_queries):\n",
    "        selected_query = search_queries[int(user_choice) - 1]\n",
    "    else:\n",
    "        print(\"âš ï¸ Invalid input. Defaulting to first query.\")\n",
    "        selected_query = search_queries[0]\n",
    "\n",
    "    print(f\"\\nðŸ”Ž Selected Query:\\n{selected_query}\\n\")\n",
    "\n",
    "    if year_range:\n",
    "        selected_query = f\"{selected_query} AND {year_range}[pdat]\"\n",
    "\n",
    "    # 3ï¸âƒ£ PubMed ê²€ìƒ‰ ìˆ˜í–‰\n",
    "    print(\"ðŸ”„ Searching PubMed...\\n\")\n",
    "    search_result = pubmed_search_tool(selected_query, max_papers)\n",
    "    search_data = json.loads(search_result)\n",
    "\n",
    "    if \"error\" in search_data:\n",
    "        print(f\"âŒ PubMed Error: {search_data['error']}\")\n",
    "        return {\"error\": search_data[\"error\"]}\n",
    "\n",
    "    papers = search_data[\"papers\"]\n",
    "    print(f\"âœ… Retrieved {len(papers)} papers (of {search_data['total_count']} total)\\n\")\n",
    "\n",
    "    # 4ï¸âƒ£ APA í˜•ì‹ ë³€í™˜\n",
    "    print(\"ðŸ“ Formatting results into APA 7th edition...\\n\")\n",
    "    papers_text = format_papers_for_prompt(papers)\n",
    "\n",
    "    apa_prompt = f\"\"\"\n",
    "You are an expert in APA 7th edition reference formatting.\n",
    "\n",
    "Task:\n",
    "Convert each paper below into numbered APA-style references.\n",
    "\n",
    "Guidelines:\n",
    "1. Journal article format â€” Author(s). (Year). Title. Journal Name, Volume(Issue), pages. DOI\n",
    "2. Use '&' before the final author name.\n",
    "3. Capitalize only the first word of the title and proper nouns.\n",
    "4. Italicize journal names and volume numbers.\n",
    "5. Include DOI if available.\n",
    "6. Output should be a numbered list, one reference per line.\n",
    "\n",
    "Papers:\n",
    "{papers_text}\n",
    "\"\"\"\n",
    "\n",
    "    apa_response = client.chat_completions_create(\n",
    "        messages=[{\"role\": \"user\", \"content\": apa_prompt}],\n",
    "        tools=[],\n",
    "        max_turns=1\n",
    "    )\n",
    "\n",
    "    apa_output = apa_response.choices[0].message.content.strip()\n",
    "\n",
    "    print(\"âœ… APA Formatting Complete!\\n\")\n",
    "\n",
    "    # 5ï¸âƒ£ APA ê²°ê³¼ë¥¼ ê° ë…¼ë¬¸ì— ë§¤í•‘\n",
    "    apa_refs = [ref.strip() for ref in apa_output.split(\"\\n\") if ref.strip()]\n",
    "    for i, paper in enumerate(papers):\n",
    "        paper[\"apa_formatted\"] = apa_refs[i] if i < len(apa_refs) else None\n",
    "\n",
    "    # 6ï¸âƒ£ ê²°ê³¼ ë°˜í™˜\n",
    "    return {\n",
    "        \"topic\": topic_info[\"structured_topic\"],\n",
    "        \"query_used\": selected_query,\n",
    "        \"papers\": papers,\n",
    "        \"apa_references\": apa_output,\n",
    "        \"raw_search_data\": search_data\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"âœ… literature_search_agent Ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Agent 1 ì‹¤í–‰í•˜ê¸°\n",
    "\n",
    "ì•„ëž˜ ì…€ì„ ì‹¤í–‰í•˜ì—¬ PubMed ê²€ìƒ‰ì„ ì‹œìž‘í•˜ì„¸ìš”.\n",
    "\n",
    "**ì„¤ì •:**\n",
    "- `max_papers`: ê²€ìƒ‰í•  ìµœëŒ€ ë…¼ë¬¸ ìˆ˜ (ê¸°ë³¸ê°’: 20)\n",
    "- `interactive`: ëŒ€í™”í˜• ëª¨ë“œ (ê¸°ë³¸ê°’: True)\n",
    "  - `True`: ì¿¼ë¦¬ ì„ íƒì„ ì‚¬ìš©ìžê°€ ì§ì ‘ ìˆ˜í–‰\n",
    "  - `False`: ìžë™ìœ¼ë¡œ ëª¨ë“  ì¿¼ë¦¬ë¥¼ ORë¡œ ê²°í•©í•˜ì—¬ ê²€ìƒ‰\n",
    "\n",
    "**ì‹¤í–‰ í›„:**\n",
    "1. ì œì•ˆëœ ê²€ìƒ‰ ì¿¼ë¦¬ê°€ ì¶œë ¥ë©ë‹ˆë‹¤ (ë” ìµœì í™”ëœ ì¿¼ë¦¬!)\n",
    "2. Interactive ëª¨ë“œì¼ ê²½ìš°:\n",
    "   - [1-N]: í•´ë‹¹ ë²ˆí˜¸ì˜ ì¿¼ë¦¬ ì„ íƒ\n",
    "   - [custom]: ì§ì ‘ ì¿¼ë¦¬ ìž…ë ¥\n",
    "   - [all]: ëª¨ë“  ì¿¼ë¦¬ë¥¼ ORë¡œ ê²°í•©\n",
    "   - [Enter]: ì²« ë²ˆì§¸ ì¿¼ë¦¬ ì‚¬ìš© (ê¸°ë³¸ê°’)\n",
    "3. ê²€ìƒ‰ì´ ì™„ë£Œë˜ë©´ ë…¼ë¬¸ ì •ë³´ì™€ APA ë ˆí¼ëŸ°ìŠ¤ê°€ ìƒì„±ë©ë‹ˆë‹¤\n",
    "4. ê° ë…¼ë¬¸ì— `apa_formatted` í•„ë“œê°€ í¬í•¨ë˜ì–´ ë§¤í•‘ë©ë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "ðŸ“š  Literature Search Agent v2 â€” PubMed & APA Formatter\n",
      "=================================================================\n",
      "\n",
      "ðŸ¤” Generating optimized PubMed queries...\n",
      "\n",
      "ðŸ“Š Suggested PubMed Queries:\n",
      "  1. 1. \"Transcranial Magnetic Stimulation AND Superior Parietal Cortex AND (Working Memory OR WM) AND Distractors\"\n",
      "  2. 2. \"(Working Memory OR WM) AND Supra-modal Memory AND Superior Parietal Cortex\"\n",
      "  3. 3. \"Transcranial Magnetic Stimulation AND Cognitive Neuroscience AND Distractors AND Brain Stimulation\"\n",
      "  4. 4. \"Brain Stimulation AND Superior Parietal Cortex AND (Working Memory OR WM)\"\n",
      "  5. 5. \"TMS AND Supra-modal Memory AND Superior Parietal Cortex AND Distractors\"\n",
      "\n",
      "ðŸ”Ž Selected Query:\n",
      "(1. \"Transcranial Magnetic Stimulation AND Superior Parietal Cortex AND (Working Memory OR WM) AND Distractors\") OR (2. \"(Working Memory OR WM) AND Supra-modal Memory AND Superior Parietal Cortex\") OR (3. \"Transcranial Magnetic Stimulation AND Cognitive Neuroscience AND Distractors AND Brain Stimulation\") OR (4. \"Brain Stimulation AND Superior Parietal Cortex AND (Working Memory OR WM)\") OR (5. \"TMS AND Supra-modal Memory AND Superior Parietal Cortex AND Distractors\")\n",
      "\n",
      "ðŸ”„ Searching PubMed...\n",
      "\n",
      "âœ… Retrieved 25 papers (of 26 total)\n",
      "\n",
      "ðŸ“ Formatting results into APA 7th edition...\n",
      "\n",
      "âœ… APA Formatting Complete!\n",
      "\n",
      "\n",
      "=================================================================\n",
      "ðŸ“š APA ë ˆí¼ëŸ°ìŠ¤ ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 5ê°œ)\n",
      "=================================================================\n",
      "1. Liu, Y., Ai, Y., Cao, J., Cheng, Q., Hu, H., Luo, J., Zeng, L., Zhang, S., Fang, J., Huang, L., Zheng, H., & Hu, X. (2024). High-frequency rTMS broadly ameliorates working memory and cognitive symptoms in stroke patients: A randomized controlled trial. *Neurorehabilitation and Neural Repair, 38*(10), 729-741. https://doi.org/10.1177/15459683241270022\n",
      "2. Xu, Y., & Chun, M. M. (2009). Selecting and perceiving multiple visual objects. *Trends in Cognitive Sciences, 13*(4), 167-174. https://doi.org/10.1016/j.tics.2009.01.008\n",
      "3. Rauh, J., MÃ¼ller, A. S. M., Nolte, G., Haaf, M., MuÃŸmann, M., Steinmann, S., Mulert, C., & Leicht, G. (2023). Comparison of transcranial brain stimulation approaches: Prefrontal theta alternating current stimulation enhances working memory performance. *Frontiers in Psychiatry, 14*, 1140361. https://doi.org/10.3389/fpsyt.2023.1140361\n",
      "4. Edin, F., Klingberg, T., StÃ¶dberg, T., & TegnÃ©r, J. (2007). Fronto-parietal connection asymmetry regulates working memory distractibility. *Journal of Integrative Neuroscience, 6*(4), 567-596.\n",
      "5. Zhao, Y. J., Zhang, X., & Ku, Y. (2024). Divergent roles of early visual cortex and inferior frontal junction in visual working memory. *Brain Stimulation, 17*(3), 713-720. https://doi.org/10.1016/j.brs.2024.06.001\n",
      "6. Michalka, S. W., Rosen, M. L., Kong, L., Shinn-Cunningham, B. G., & Somers, D. C. (2016). Auditory spatial coding flexibly recruits anterior, but not posterior, visuotopic parietal cortex. *Cerebral Cortex, 26*(3), 1302-1308. https://doi.org/10.1093/cercor/bhv303\n",
      "7. Yue, Q., & Martin, R. C. (2022). Phonological working memory representations in the left inferior parietal lobe in the face of distraction and neural stimulation. *Frontiers in Human Neuroscience, 16*, 890483. https://doi.org/10.3389/fnhum.2022.890483\n",
      "8. Manaia, F., Rocha, K., Marinho, V., MagalhÃ£es, F., Oliveira, T., Carvalho, V., AraÃºjo, T., Ayres, C., Gupta, D., Velasques, B., Ribeiro, P., Cagy, M., Bastos, V. H., & Teixeira, S. (2019). The role of low-frequency rTMS in the superior parietal cortex during time estimation. *Neurological Sciences, 40*(6), 1183-1189. https://doi.org/10.1007/s10072-019-03820-8\n",
      "\n",
      "=================================================================\n",
      "ðŸ“Š ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½\n",
      "=================================================================\n",
      "ì‚¬ìš©ëœ ì¿¼ë¦¬: (1. \"Transcranial Magnetic Stimulation AND Superior Parietal Cortex AND (Working Memory OR WM) AND Distractors\") OR (2. \"(Working Memory OR WM) AND Supra-modal Memory AND Superior Parietal Cortex\") OR (3. \"Transcranial Magnetic Stimulation AND Cognitive Neuroscience AND Distractors AND Brain Stimulation\") OR (4. \"Brain Stimulation AND Superior Parietal Cortex AND (Working Memory OR WM)\") OR (5. \"TMS AND Supra-modal Memory AND Superior Parietal Cortex AND Distractors\") AND 2000:2025[pdat]\n",
      "ê²€ìƒ‰ëœ ë…¼ë¬¸ ìˆ˜: 25ê°œ\n",
      "ê° ë…¼ë¬¸ì— APA í˜•ì‹ ë§¤í•‘ ì™„ë£Œ: âœ“\n"
     ]
    }
   ],
   "source": [
    "# ê²€ìƒ‰í•  ìµœëŒ€ ë…¼ë¬¸ ìˆ˜ ì„¤ì •\n",
    "max_papers = 25\n",
    "\n",
    "# ëŒ€í™”í˜• ëª¨ë“œ ì„¤ì • (True: ì‚¬ìš©ìžê°€ ì„ íƒ, False: ìžë™ìœ¼ë¡œ ëª¨ë“  ì¿¼ë¦¬ ê²°í•©)\n",
    "interactive_mode = False\n",
    "year = \"2000:2025\"\n",
    "\n",
    "# Agent 0ì˜ ê²°ê³¼ í™•ì¸ (topic_infoê°€ ì—†ìœ¼ë©´ íŒŒì¼ì—ì„œ ì½ê¸°)\n",
    "try:\n",
    "    if 'topic_info' not in locals() or topic_info is None:\n",
    "        raise NameError(\"topic_info not defined\")\n",
    "except NameError:\n",
    "    print(\"âš ï¸ topic_infoê°€ ì •ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Agent 0 ê²°ê³¼ íŒŒì¼ì„ ì°¾ëŠ” ì¤‘...\\n\")\n",
    "    import glob\n",
    "    topic_files = glob.glob(\"agent0_topic_definition_*.txt\")\n",
    "    if topic_files:\n",
    "        topic_files.sort(reverse=True)\n",
    "        topic_filename_load = topic_files[0]\n",
    "        with open(topic_filename_load, \"r\", encoding=\"utf-8\") as f:\n",
    "            content = f.read()\n",
    "        # topic_info ìž¬êµ¬ì„±\n",
    "        parts = content.split(\"=\"*65)\n",
    "        if len(parts) >= 2:\n",
    "            user_input_part = parts[0].replace(\"User Input:\", \"\").strip()\n",
    "            structured_part = parts[2].strip() if len(parts) > 2 else parts[1].strip()\n",
    "            structured_part = structured_part.replace(\"Structured Topic Information:\", \"\").strip()\n",
    "            topic_info = {\n",
    "                \"user_input\": user_input_part,\n",
    "                \"structured_topic\": structured_part\n",
    "            }\n",
    "            print(f\"âœ… Agent 0 ê²°ê³¼ íŒŒì¼ ë¡œë“œ: {topic_filename_load}\\n\")\n",
    "        else:\n",
    "            raise ValueError(\"Agent 0 íŒŒì¼ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "    else:\n",
    "        raise FileNotFoundError(\"Agent 0 ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Agent 0ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
    "\n",
    "# Agent 1 v2 ì‹¤í–‰\n",
    "search_result = literature_search_agent(\n",
    "    topic_info=topic_info,\n",
    "    max_papers=max_papers,\n",
    "    interactive=interactive_mode,\n",
    "    year_range=year\n",
    ")\n",
    "\n",
    "# ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°\n",
    "if \"error\" not in search_result:\n",
    "    print(\"\\n\" + \"=\"*65)\n",
    "    print(\"ðŸ“š APA ë ˆí¼ëŸ°ìŠ¤ ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 5ê°œ)\")\n",
    "    print(\"=\"*65)\n",
    "    lines = search_result[\"apa_references\"].split(\"\\n\")\n",
    "    for line in lines[:15]:\n",
    "        if line.strip():\n",
    "            print(line)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*65)\n",
    "    print(\"ðŸ“Š ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½\")\n",
    "    print(\"=\"*65)\n",
    "    print(f\"ì‚¬ìš©ëœ ì¿¼ë¦¬: {search_result['query_used']}\")\n",
    "    print(f\"ê²€ìƒ‰ëœ ë…¼ë¬¸ ìˆ˜: {len(search_result['papers'])}ê°œ\")\n",
    "    print(f\"ê° ë…¼ë¬¸ì— APA í˜•ì‹ ë§¤í•‘ ì™„ë£Œ: âœ“\")\n",
    "else:\n",
    "    print(\"âŒ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š ê²€ìƒ‰ ê²°ê³¼ë¥¼ í‘œì™€ íŒŒì¼ë¡œ ì €ìž¥í•˜ê¸°\n",
    "\n",
    "Agent 1ì˜ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë‹¤ì–‘í•œ í˜•ì‹ìœ¼ë¡œ ì €ìž¥í•˜ê³  ì‹œê°í™”í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ì €ìž¥ë˜ëŠ” íŒŒì¼:\n",
    "1. **JSON íŒŒì¼** (`papers_search_[timestamp].json`)\n",
    "   - ì „ì²´ ê²€ìƒ‰ ê²°ê³¼ (ëª¨ë“  ë©”íƒ€ë°ì´í„° í¬í•¨)\n",
    "   - í”„ë¡œê·¸ëž¨ì—ì„œ ìž¬ì‚¬ìš© ê°€ëŠ¥í•œ í˜•ì‹\n",
    "\n",
    "2. **CSV íŒŒì¼** (`papers_table_[timestamp].csv`)\n",
    "   - í‘œ í˜•ì‹ì˜ ë…¼ë¬¸ ì •ë³´\n",
    "   - Excelì´ë‚˜ ë‹¤ë¥¸ ë„êµ¬ì—ì„œ ì—´ê¸° ê°€ëŠ¥\n",
    "\n",
    "3. **Excel íŒŒì¼** (`papers_table_[timestamp].xlsx`) - ì„ íƒì‚¬í•­\n",
    "   - ì„œì‹ì´ ì ìš©ëœ í‘œ í˜•ì‹\n",
    "   - pandasì™€ openpyxl í•„ìš”\n",
    "\n",
    "### í‘œì— í¬í•¨ë˜ëŠ” ì •ë³´:\n",
    "- PMID (PubMed ID)\n",
    "- ì œëª© (Title)\n",
    "- ì²« ë²ˆì§¸ ì €ìž (First Author)\n",
    "- ë…„ë„ (Year)\n",
    "- ì €ë„ (Journal)\n",
    "- DOI\n",
    "- APA í˜•ì‹ ë ˆí¼ëŸ°ìŠ¤\n",
    "\n",
    "**ì‹¤í–‰:**\n",
    "ì•„ëž˜ ì…€ì„ ì‹¤í–‰í•˜ì—¬ ê²°ê³¼ë¥¼ ì €ìž¥í•˜ê³  í‘œë¡œ í™•ì¸í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "ðŸ’¾ ê²€ìƒ‰ ê²°ê³¼ ì €ìž¥ ì¤‘...\n",
      "=================================================================\n",
      "\n",
      "âœ… JSON íŒŒì¼ ì €ìž¥: papers_search_20251104_104847.json\n",
      "   - ì „ì²´ ê²€ìƒ‰ ê²°ê³¼ (ë©”íƒ€ë°ì´í„° í¬í•¨)\n",
      "   - ì‚¬ìš©ëœ ì¿¼ë¦¬: (1. \"Transcranial Magnetic Stimulation AND Superior Parietal Cortex AND (Working Memory OR WM) AND Distractors\") OR (2. \"(Working Memory OR WM) AND Supra-modal Memory AND Superior Parietal Cortex\") OR (3. \"Transcranial Magnetic Stimulation AND Cognitive Neuroscience AND Distractors AND Brain Stimulation\") OR (4. \"Brain Stimulation AND Superior Parietal Cortex AND (Working Memory OR WM)\") OR (5. \"TMS AND Supra-modal Memory AND Superior Parietal Cortex AND Distractors\") AND 2000:2025[pdat]\n",
      "   - ë…¼ë¬¸ ìˆ˜: 25ê°œ\n",
      "\n",
      "âœ… CSV íŒŒì¼ ì €ìž¥: papers_table_20251104_104847.csv\n",
      "   - Excelì—ì„œ ì—´ê¸° ê°€ëŠ¥í•œ í‘œ í˜•ì‹\n",
      "\n",
      "â„¹ï¸  Excel ì €ìž¥ ê±´ë„ˆë›°ê¸° (openpyxlì´ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ)\n",
      "   ì„¤ì¹˜: pip install openpyxl\n",
      "\n",
      "\n",
      "=================================================================\n",
      "ðŸ“‹ ê²€ìƒ‰ëœ ë…¼ë¬¸ ëª©ë¡ (í‘œ í˜•ì‹)\n",
      "=================================================================\n",
      "\n",
      "        PMID                                                                                                                                                                                          Title   First Author  Year                                                                                                                              Journal\n",
      "0   39162240                                                               High-Frequency rTMS Broadly Ameliorates Working Memory and Cognitive Symptoms in Stroke Patients: A Randomized Controlled Trial.          Liu Y  2024                                                                                                Neurorehabilitation and neural repair\n",
      "1   19269882                                                                                                                                              Selecting and perceiving multiple visual objects.           Xu Y  2009                                                                                                         Trends in cognitive sciences\n",
      "2   37457770                                                 Comparison of transcranial brain stimulation approaches: prefrontal theta alternating current stimulation enhances working memory performance.         Rauh J  2023                                                                                                              Frontiers in psychiatry\n",
      "3   18181269                                                                                                                 Fronto-parietal connection asymmetry regulates working memory distractibility.         Edin F  2007                                                                                                  Journal of integrative neuroscience\n",
      "4   38839040                                                                                                 Divergent roles of early visual cortex and inferior frontal junction in visual working memory.        Zhao YJ  2024                                                                                                                    Brain stimulation\n",
      "5   26656996                                                                                             Auditory Spatial Coding Flexibly Recruits Anterior, but Not Posterior, Visuotopic Parietal Cortex.    Michalka SW  2016                                                                                              Cerebral cortex (New York, N.Y. : 1991)\n",
      "6   35814962                                                              Phonological Working Memory Representations in the Left Inferior Parietal Lobe in the Face of Distraction and Neural Stimulation.          Yue Q  2022                                                                                                      Frontiers in human neuroscience\n",
      "7   30850896                                                                                                         The role of low-frequency rTMS in the superior parietal cortex during time estimation.       Manaia F  2019  Neurological sciences : official journal of the Italian Neurological Society and of the Italian Society of Clinical Neurophysiology\n",
      "8   17448605                                                                                               Temporal modeling demonstrates preserved overlearning processes in schizophrenia: an fMRI study.         Koch K  2007                                                                                                                         Neuroscience\n",
      "9   15202106                                                                                                     Cross-modal temporal order memory for auditory digits and visual locations: an fMRI study.        Zhang D  2004                                                                                                                  Human brain mapping\n",
      "10  28959194                                                                              Theta and Alpha Oscillations during the Retention Period of Working Memory by rTMS Stimulating the Parietal Lobe.           Li S  2017                                                                                                 Frontiers in behavioral neuroscience\n",
      "11  29522178                                                               Non-perceptual Regions in the Left Inferior Parietal Lobe Support Phonological Short-term Memory: Evidence for a Buffer Account?          Yue Q  2019                                                                                              Cerebral cortex (New York, N.Y. : 1991)\n",
      "12  15038006                                                                                   Neural correlates of switching set as measured in fast, event-related functional magnetic resonance imaging.       Smith AB  2004                                                                                                                  Human brain mapping\n",
      "13  19686473                                                                          A systematic fMRI investigation of the brain systems subserving different working memory components in schizophrenia.     Henseler I  2009                                                                                                 The European journal of neuroscience\n",
      "14  29876962                                                                                        Impact of transcranial direct current stimulation on structural plasticity of the somatosensory system.        Hirtz R  2018                                                                                                     Journal of neuroscience research\n",
      "15  23721725                                                                                                                                    Structural connectivity of visuotopic intraparietal sulcus.         Bray S  2013                                                                                                                           NeuroImage\n",
      "16  23319041                                                                                                    Neural correlates of spatial working memory load in a delayed match-to-sample saccade task.        Raabe M  2013                                                                                                                           NeuroImage\n",
      "17  12948700                                                                                      Dynamics of working memory for moving sounds: an event-related potential and scalp current density study.       Kaiser J  2003                                                                                                                           NeuroImage\n",
      "18  18177676                                                                   Functional developmental similarities and differences in the neural correlates of verbal and nonverbal working memory tasks.  Brahmbhatt SB  2008                                                                                                                     Neuropsychologia\n",
      "19  20714061                                                                                                      Modality specific cerebro-cerebellar activations in verbal working memory: an fMRI study.    Kirschen MP  2010                                                                                                                Behavioural neurology\n",
      "20  20350181                                                                   The neural substrates of recognition memory for verbal information: spanning the divide between short- and long-term memory.   Buchsbaum BR  2011                                                                                                    Journal of cognitive neuroscience\n",
      "21  12948699                                                                                                               Functional anatomy of pitch memory--an fMRI study with sparse temporal sampling.         Gaab N  2003                                                                                                                           NeuroImage\n",
      "22  40216305                                                        Affective state-dependent effects of prefrontal rTMS on the cognitive control of negative stimuli in healthy and depressed individuals.       Paneva J  2025                                                                                                                    Brain stimulation\n",
      "23  21699481                                   Surgery for gliomas involving the left inferior parietal lobule: new insights into the functional anatomy provided by stimulation mapping in awake patients.   Maldonado IL  2011                                                                                                              Journal of neurosurgery\n",
      "24  12377177  Separating relational from item load effects in paired recognition: temporoparietal and middle frontal gyral activity with increased associates, but not items during encoding and retention.     Phillips S  2002                                                                                                                           NeuroImage\n",
      "\n",
      "=================================================================\n",
      "ðŸ“Š í†µê³„ ì •ë³´\n",
      "=================================================================\n",
      "ì´ ë…¼ë¬¸ ìˆ˜: 25ê°œ\n",
      "ë…„ë„ ë²”ìœ„: 2002 - 2025\n",
      "\n",
      "ì£¼ìš” ì €ë„ ë¶„í¬:\n",
      "  - NeuroImage: 5ê°œ\n",
      "  - Human brain mapping: 2ê°œ\n",
      "  - Brain stimulation: 2ê°œ\n",
      "  - Cerebral cortex (New York, N.Y. : 1991): 2ê°œ\n",
      "  - Frontiers in behavioral neuroscience: 1ê°œ\n",
      "\n",
      "ë…„ë„ë³„ ë¶„í¬:\n",
      "  - 2025: 1ê°œ\n",
      "  - 2024: 2ê°œ\n",
      "  - 2023: 1ê°œ\n",
      "  - 2022: 1ê°œ\n",
      "  - 2019: 2ê°œ\n",
      "  - 2018: 1ê°œ\n",
      "  - 2017: 1ê°œ\n",
      "  - 2016: 1ê°œ\n",
      "  - 2013: 2ê°œ\n",
      "  - 2011: 2ê°œ\n",
      "\n",
      "=================================================================\n",
      "ðŸŽ‰ ëª¨ë“  íŒŒì¼ ì €ìž¥ ì™„ë£Œ!\n",
      "=================================================================\n",
      "\n",
      "ðŸ“ ì €ìž¥ëœ íŒŒì¼:\n",
      "  - papers_search_20251104_104847.json\n",
      "  - papers_table_20251104_104847.csv\n",
      "  - papers_table_20251104_104847.xlsx\n"
     ]
    }
   ],
   "source": [
    "# íƒ€ìž„ìŠ¤íƒ¬í”„ ìƒì„±\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "if \"error\" not in search_result:\n",
    "    print(\"\\n\" + \"=\"*65)\n",
    "    print(\"ðŸ’¾ ê²€ìƒ‰ ê²°ê³¼ ì €ìž¥ ì¤‘...\")\n",
    "    print(\"=\"*65 + \"\\n\")\n",
    "    \n",
    "    # ==============================\n",
    "    # 1. JSON íŒŒì¼ë¡œ ì „ì²´ ê²°ê³¼ ì €ìž¥\n",
    "    # ==============================\n",
    "    json_filename = f\"papers_search_{timestamp}.json\"\n",
    "    with open(json_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(search_result, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"âœ… JSON íŒŒì¼ ì €ìž¥: {json_filename}\")\n",
    "    print(f\"   - ì „ì²´ ê²€ìƒ‰ ê²°ê³¼ (ë©”íƒ€ë°ì´í„° í¬í•¨)\")\n",
    "    print(f\"   - ì‚¬ìš©ëœ ì¿¼ë¦¬: {search_result['query_used']}\")\n",
    "    print(f\"   - ë…¼ë¬¸ ìˆ˜: {len(search_result['papers'])}ê°œ\\n\")\n",
    "    \n",
    "    # ==============================\n",
    "    # 2. DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "    # ==============================\n",
    "    papers_data = []\n",
    "    for paper in search_result[\"papers\"]:\n",
    "        papers_data.append({\n",
    "            \"PMID\": paper.get(\"pmid\", \"\"),\n",
    "            \"Title\": paper.get(\"title\", \"\"),\n",
    "            \"First Author\": paper.get(\"first_author\", \"\"),\n",
    "            \"All Authors\": \", \".join(paper.get(\"authors\", [])[:3]) + (\"...\" if len(paper.get(\"authors\", [])) > 3 else \"\"),\n",
    "            \"Year\": paper.get(\"year\", \"\"),\n",
    "            \"Journal\": paper.get(\"journal\", \"\"),\n",
    "            \"Volume\": paper.get(\"volume\", \"\"),\n",
    "            \"Issue\": paper.get(\"issue\", \"\"),\n",
    "            \"Pages\": paper.get(\"pages\", \"\"),\n",
    "            \"DOI\": paper.get(\"doi\", \"\"),\n",
    "            \"APA Format\": paper.get(\"apa_formatted\", \"\")\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(papers_data)\n",
    "    \n",
    "    # ==============================\n",
    "    # 3. CSV íŒŒì¼ë¡œ ì €ìž¥\n",
    "    # ==============================\n",
    "    csv_filename = f\"papers_table_{timestamp}.csv\"\n",
    "    df.to_csv(csv_filename, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"âœ… CSV íŒŒì¼ ì €ìž¥: {csv_filename}\")\n",
    "    print(f\"   - Excelì—ì„œ ì—´ê¸° ê°€ëŠ¥í•œ í‘œ í˜•ì‹\\n\")\n",
    "    \n",
    "    # ==============================\n",
    "    # 4. Excel íŒŒì¼ë¡œ ì €ìž¥ (ì„ íƒì‚¬í•­)\n",
    "    # ==============================\n",
    "    try:\n",
    "        excel_filename = f\"papers_table_{timestamp}.xlsx\"\n",
    "        df.to_excel(excel_filename, index=False, engine='openpyxl')\n",
    "        print(f\"âœ… Excel íŒŒì¼ ì €ìž¥: {excel_filename}\")\n",
    "        print(f\"   - ì„œì‹ì´ ì ìš©ëœ í‘œ í˜•ì‹\\n\")\n",
    "    except ImportError:\n",
    "        print(\"â„¹ï¸  Excel ì €ìž¥ ê±´ë„ˆë›°ê¸° (openpyxlì´ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ)\")\n",
    "        print(\"   ì„¤ì¹˜: pip install openpyxl\\n\")\n",
    "    \n",
    "    # ==============================\n",
    "    # 5. í‘œ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥\n",
    "    # ==============================\n",
    "    print(\"\\n\" + \"=\"*65)\n",
    "    print(\"ðŸ“‹ ê²€ìƒ‰ëœ ë…¼ë¬¸ ëª©ë¡ (í‘œ í˜•ì‹)\")\n",
    "    print(\"=\"*65 + \"\\n\")\n",
    "    \n",
    "    # ì»¬ëŸ¼ í­ ì„¤ì •í•˜ì—¬ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.width', None)\n",
    "    \n",
    "    # ìš”ì•½ í‘œ ì¶œë ¥ (ì£¼ìš” ì»¬ëŸ¼ë§Œ)\n",
    "    summary_df = df[[\"PMID\", \"Title\", \"First Author\", \"Year\", \"Journal\"]].copy()\n",
    "    print(summary_df.to_string(index=True))\n",
    "    \n",
    "    # ==============================\n",
    "    # 6. í†µê³„ ì •ë³´\n",
    "    # ==============================\n",
    "    print(\"\\n\" + \"=\"*65)\n",
    "    print(\"ðŸ“Š í†µê³„ ì •ë³´\")\n",
    "    print(\"=\"*65)\n",
    "    print(f\"ì´ ë…¼ë¬¸ ìˆ˜: {len(df)}ê°œ\")\n",
    "    print(f\"ë…„ë„ ë²”ìœ„: {df['Year'].min()} - {df['Year'].max()}\")\n",
    "    print(f\"\\nì£¼ìš” ì €ë„ ë¶„í¬:\")\n",
    "    journal_counts = df['Journal'].value_counts().head(5)\n",
    "    for journal, count in journal_counts.items():\n",
    "        print(f\"  - {journal[:50]}: {count}ê°œ\")\n",
    "    \n",
    "    print(f\"\\në…„ë„ë³„ ë¶„í¬:\")\n",
    "    year_counts = df['Year'].value_counts().sort_index(ascending=False).head(10)\n",
    "    for year, count in year_counts.items():\n",
    "        print(f\"  - {year}: {count}ê°œ\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*65)\n",
    "    print(\"ðŸŽ‰ ëª¨ë“  íŒŒì¼ ì €ìž¥ ì™„ë£Œ!\")\n",
    "    print(\"=\"*65)\n",
    "    print(f\"\\nðŸ“ ì €ìž¥ëœ íŒŒì¼:\")\n",
    "    print(f\"  - {json_filename}\")\n",
    "    print(f\"  - {csv_filename}\")\n",
    "    try:\n",
    "        print(f\"  - {excel_filename}\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì–´ ì €ìž¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 6. Agent 2: Introduction ìž‘ì„± ì—ì´ì „íŠ¸\n",
    "\n",
    "## âœï¸ í•™ìˆ  ë…¼ë¬¸ Introduction ìžë™ ìƒì„±\n",
    "\n",
    "ì´ ì—ì´ì „íŠ¸ëŠ” ê²€ìƒ‰ëœ ë…¼ë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ êµ¬ì¡°í™”ëœ Introductionì„ ìž‘ì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "### Introduction êµ¬ì¡°:\n",
    "\n",
    "#### **1. ë©”ì¸ í† í”½ ì†Œê°œ ë° ë°°ê²½** (2-3 ë¬¸ë‹¨)\n",
    "- ì—°êµ¬ ë¶„ì•¼ì˜ ë„“ì€ ë§¥ë½ ì„¤ëª…\n",
    "- ì™œ ì´ ì£¼ì œê°€ ì¤‘ìš”í•œê°€?\n",
    "- ì „ë°˜ì ì¸ ì—°êµ¬ í˜„í™©\n",
    "\n",
    "#### **2. í˜„ìž¬ ì—°êµ¬ ë™í–¥** (2-3 ë¬¸ë‹¨)\n",
    "- ê²€ìƒ‰ëœ ë…¼ë¬¸ì˜ ì£¼ìš” ë°œê²¬ì‚¬í•­ ë¦¬ë·°\n",
    "- ì—°êµ¬ íŒ¨í„´ê³¼ í…Œë§ˆ ì‹ë³„\n",
    "- **ë…¼ë¬¸ ì¸ìš© í¬í•¨**: (Author, Year) í˜•ì‹\n",
    "\n",
    "#### **3. Research Gap** (1-2 ë¬¸ë‹¨)\n",
    "- í˜„ìž¬ ì—°êµ¬ì—ì„œ í•´ê²°ë˜ì§€ ì•Šì€ ë¬¸ì œ\n",
    "- ê¸°ì¡´ ì ‘ê·¼ë²•ì˜ í•œê³„\n",
    "- ì™œ ì´ gapì´ ì¤‘ìš”í•œê°€?\n",
    "\n",
    "#### **4. í˜„ìž¬ ì—°êµ¬ì˜ í•„ìš”ì„±** (1-2 ë¬¸ë‹¨)\n",
    "- ì´ ì—°êµ¬ê°€ gapì„ ì–´ë–»ê²Œ í•´ê²°í•˜ëŠ”ê°€\n",
    "- ì—°êµ¬ ëª©í‘œ\n",
    "- ê¸°ëŒ€ë˜ëŠ” ê¸°ì—¬\n",
    "### ìž‘ì„± ì›ì¹™:\n",
    "- **í˜•ì‹ì  í•™ìˆ  ì˜ì–´** ì‚¬ìš©\n",
    "- **(First Author Last Name, Year)** í˜•ì‹ìœ¼ë¡œ ì¸ìš©\n",
    "- ê²€ìƒ‰ëœ ë…¼ë¬¸ì—ì„œ ì €ìžì™€ ë…„ë„ ì¶”ì¶œí•˜ì—¬ ì¸ìš©\n",
    "- ë¬¸ë‹¨ ê°„ ìžì—°ìŠ¤ëŸ¬ìš´ ì „í™˜\n",
    "- ê°ê´€ì , 3ì¸ì¹­ ì–´ì¡° ìœ ì§€\n",
    "- ì•½ 1000-1500 ë‹¨ì–´ ë¶„ëŸ‰\n",
    "\n",
    "**ì‹¤í–‰ ë°©ë²•:**\n",
    "1. Agent 0ê³¼ Agent 1ì´ ë¨¼ì € ì‹¤í–‰ë˜ì–´ ìžˆì–´ì•¼ í•©ë‹ˆë‹¤\n",
    "2. ì‹¤í–‰í•˜ë©´ 1-2ë¶„ ì •ë„ ì†Œìš”ë©ë‹ˆë‹¤\n",
    "3. ì™„ì„±ëœ Introductionì´ ì¶œë ¥ë©ë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Introduction ìž‘ì„± ì—ì´ì „íŠ¸ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n",
      "\n",
      "============================================================\n",
      "âœï¸ Introduction ìž‘ì„± ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘...\n",
      "============================================================\n",
      "\n",
      "ðŸ”„ Introduction ìž‘ì„± ì¤‘ (1-2ë¶„ ì†Œìš”)...\n",
      "âœ… Introduction ìž‘ì„± ì™„ë£Œ\n",
      "\n",
      "\n",
      "=================================================================\n",
      "ðŸ’¾ Agent 2 ê²°ê³¼ ì €ìž¥ ì™„ë£Œ\n",
      "=================================================================\n",
      "íŒŒì¼ëª…: agent2_introduction_draft_20251104_013725.txt\n",
      "\n",
      "\n",
      "=================================================================\n",
      "ðŸ“„ Introduction ì´ˆì•ˆ (ì „ì²´)\n",
      "=================================================================\n",
      "\n",
      "**Introduction to the Main Topic**\n",
      "\n",
      "In the intricate network of the human brain, the Superior Parietal Cortex (SPC) plays a crucial role in cognitive functions, particularly in working memory and sensory integration. Situated in the posterior part of the brain, the SPC is pivotal in modulating attention and facilitating the retention of information across multiple sensory modalitiesâ€”a phenomenon known as supra-modal memory. Understanding the underlying mechanisms of this process is essential, as working memory is foundational to higher-order cognitive functions such as problem-solving and planning. The intricate dynamics between neural circuits in the SPC and their role in memory retention and attentional control continue to captivate neuroscience researchers seeking to delineate the brain's complex functions.\n",
      "\n",
      "Transcranial Magnetic Stimulation (TMS) has emerged as a powerful tool for exploring causal relationships between neural activity and cognitive processes. By delivering magnetic pulses to targeted brain regions, TMS can transiently disrupt neural activity, offering insights into the functioning and connectivity of specific areas. In the context of working memory, researchers have used TMS to investigate its effects on tasks requiring the retention and manipulation of information. Interruptions or enhancements in cognitive performance, resulting from TMS application, elucidate the contributions of specific brain regions, such as the SPC, to working memory. Given the presence of distractors and other challenges to cognitive load, understanding how the SPC manages such disruptions can enhance our knowledge of cognitive resilience and adaptability in an ever-changing environment.\n",
      "\n",
      "**Current Research Trends**\n",
      "\n",
      "Research in cognitive neuroscience increasingly focuses on the intersections between brain stimulation techniques and cognitive processes. For instance, Liu et al. (2024) demonstrated that high-frequency repetitive TMS (rTMS) has broad ameliorating effects on working memory among stroke patients, suggesting potential therapeutic applications. Similarly, studies by Arciniega et al. (2018) found that frontoparietal transcranial Direct Current Stimulation (tDCS) could benefit visual working memory in older adults, highlighting age-related considerations in memory retention.\n",
      "\n",
      "Moreover, functional connectivity research reveals intriguing insights into the SPC's role. Hwang et al. (2020) showed that the human intraparietal sulcusâ€”part of the parietal cortexâ€”modulates task-evoked functional connectivity, thereby influencing working memory performance. Such studies underscore the importance of the SPC in modulating information processing across tasks with varying cognitive demands. Additionally, Romei et al. (2011) linked distinct brain frequencies to global versus local visual processing through rhythmic TMS over the parietal cortex, emphasizing the SPC's involvement in perceptual dimensions of cognitive processing.\n",
      "\n",
      "The application of TMS has also shed light on specific and nonspecific neural activities during working memory tasks. Oh and Leung (2010) examined the cortical underpinnings involved in processing visual representations, underscoring the interplay between selective attention and memory retention. This growing body of research illustrates a thematic focus on understanding the interactions between brain stimulation, neural connectivity, and cognitive function.\n",
      "\n",
      "**Research Gap**\n",
      "\n",
      "Despite the considerable advances in understanding the SPC's role in cognitive functions, several unresolved questions remain. The precise causal pathways linking supra-modal memory retention to SPC activity, especially under conditions involving distractors, require further elucidation. Existing studies often focus on isolated aspects of working memory or employ uniform experimental conditions, neglecting the complexities of multi-modal interference and cognitive distractors that individuals encounter in real-world settings. Furthermore, while TMS offers a non-invasive means to probe these neural circuits, there is limited consensus on its effects' variability across different cognitive tasks and contexts.\n",
      "\n",
      "This gap is particularly pertinent in creating more effective therapeutic approaches for cognitive impairments. As highlighted by Proskovec et al. (2018), oscillatory dynamics in the prefrontal and superior temporal cortices correlate with spatial working memory performance, yet the precise mechanisms by which the SPC modulates these dynamics remain inadequately explored. Addressing these limitations is crucial for developing more sophisticated models of cognitive functioning and targeted interventions.\n",
      "\n",
      "**Need for the Current Study**\n",
      "\n",
      "The present study aims to address these gaps by investigating the causal relationship between supra-modal memory retention and SPC activity through the lens of TMS application. By specifically examining working memory performance in the presence or absence of distractors, this research seeks to unravel the nuanced interactions within the SPC and its influence on cognitive resilience. The use of TMS provides a unique opportunity to causally probe these relationships, offering insights into both the normative functioning and potential dysregulation observed in clinical populations.\n",
      "\n",
      "With these objectives, the study aspires to contribute a more comprehensive understanding of the SPC's role in cognitive processing, bridging the divide between theoretical neuroscience and practical applications. Highlighting the factors that influence working memory amidst cognitive challenges may inform strategies to enhance cognitive health and performance across diverse populations, positioning this research at the forefront of innovative interventions aimed at optimizing brain function.\n",
      "\n",
      "By addressing these aims, this study not only enhances our theoretical understanding of cognitive neuroscience but also endeavors to have tangible impacts on the methodologies employed to assess and support cognitive functions in real-world scenarios. This research promises to deepen the scientific community's comprehension of complex neural processes, positioning itself as a critical contribution to the ongoing pursuit of cognitive enhancement and rehabilitation.\n",
      "\n",
      "=================================================================\n",
      "ðŸ“Š í†µê³„\n",
      "=================================================================\n",
      "ì „ì²´ ê¸¸ì´: 6269 ê¸€ìž\n",
      "ë‹¨ì–´ ìˆ˜: ì•½ 829 ë‹¨ì–´\n",
      "ë¬¸ë‹¨ ìˆ˜: ì•½ 13 ê°œ\n",
      "ì €ìž¥ íŒŒì¼: agent2_introduction_draft_20251104_013725.txt\n"
     ]
    }
   ],
   "source": [
    "# Agent 0 ê²°ê³¼ í™•ì¸ (topic_info)\n",
    "try:\n",
    "    if 'topic_info' not in locals() or topic_info is None:\n",
    "        raise NameError(\"topic_info not defined\")\n",
    "except NameError:\n",
    "    print(\"âš ï¸ topic_infoê°€ ì •ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Agent 0 ê²°ê³¼ íŒŒì¼ì„ ì°¾ëŠ” ì¤‘...\\n\")\n",
    "    import glob\n",
    "    topic_files = glob.glob(\"agent0_topic_definition_*.txt\")\n",
    "    if topic_files:\n",
    "        topic_files.sort(reverse=True)\n",
    "        with open(topic_files[0], \"r\", encoding=\"utf-8\") as f:\n",
    "            content = f.read()\n",
    "        parts = content.split(\"=\"*65)\n",
    "        if len(parts) >= 2:\n",
    "            user_input_part = parts[0].replace(\"User Input:\", \"\").strip()\n",
    "            structured_part = parts[2].strip() if len(parts) > 2 else parts[1].strip()\n",
    "            structured_part = structured_part.replace(\"Structured Topic Information:\", \"\").strip()\n",
    "            topic_info = {\n",
    "                \"user_input\": user_input_part,\n",
    "                \"structured_topic\": structured_part\n",
    "            }\n",
    "            print(f\"âœ… Agent 0 ê²°ê³¼ ë¡œë“œ: {topic_files[0]}\")\n",
    "    else:\n",
    "        raise FileNotFoundError(\"Agent 0 ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# Agent 1 ê²°ê³¼ í™•ì¸ (search_result)\n",
    "try:\n",
    "    if 'search_result' not in locals() or search_result is None:\n",
    "        raise NameError(\"search_result not defined\")\n",
    "except NameError:\n",
    "    print(\"âš ï¸ search_resultê°€ ì •ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Agent 1 ê²°ê³¼ íŒŒì¼ì„ ì°¾ëŠ” ì¤‘...\\n\")\n",
    "    import glob\n",
    "    json_files = glob.glob(\"papers_search_*.json\")\n",
    "    if json_files:\n",
    "        json_files.sort(reverse=True)\n",
    "        with open(json_files[0], \"r\", encoding=\"utf-8\") as f:\n",
    "            search_result = json.load(f)\n",
    "        print(f\"âœ… Agent 1 ê²°ê³¼ ë¡œë“œ: {json_files[0]}\")\n",
    "    else:\n",
    "        raise FileNotFoundError(\"Agent 1 ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Agent 1ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
    "\n",
    "print()\n",
    "\n",
    "# íƒ€ìž„ìŠ¤íƒ¬í”„ ìƒì„±\n",
    "timestamp_agent2 = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "def introduction_writer_agent(\n",
    "    topic_info: Dict[str, Any],\n",
    "    search_result: Dict[str, Any]\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Introduction ìž‘ì„± ì—ì´ì „íŠ¸\n",
    "    \n",
    "    Args:\n",
    "        topic_info (dict): í† í”½ ì •ì˜ ê²°ê³¼\n",
    "        search_result (dict): ë¬¸í—Œ ê²€ìƒ‰ ê²°ê³¼\n",
    "    \n",
    "    Returns:\n",
    "        str: ìž‘ì„±ëœ Introduction\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"âœï¸ Introduction ìž‘ì„± ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘...\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    papers_summary = json.dumps(search_result[\"papers\"][:15], indent=2, ensure_ascii=False)\n",
    "    \n",
    "    intro_prompt = f\"\"\"\n",
    "You are an expert academic writer specializing in scientific papers.\n",
    "\n",
    "Research Topic:\n",
    "{topic_info['structured_topic']}\n",
    "\n",
    "Literature Review:\n",
    "{papers_summary}\n",
    "\n",
    "Your task:\n",
    "Write a comprehensive Introduction section following this structure:\n",
    "\n",
    "1. **Introduction to the main topic** (2-3 paragraphs)\n",
    "   - Broad context and background\n",
    "   - Why this topic matters\n",
    "   - General state of the field\n",
    "\n",
    "2. **Current research trends** (2-3 paragraphs)\n",
    "   - Review key findings from the literature\n",
    "   - Identify patterns and themes\n",
    "   - Cite papers using (Author, Year) format\n",
    "   - Extract author names and years from the provided papers\n",
    "\n",
    "3. **Research gap** (1-2 paragraphs)\n",
    "   - What remains unresolved or understudied?\n",
    "   - Limitations of current approaches\n",
    "   - Why this gap matters\n",
    "\n",
    "4. **Need for the current study** (1-2 paragraphs)\n",
    "   - How this study addresses the gap\n",
    "   - Research objectives\n",
    "   - Expected contributions\n",
    "\n",
    "Requirements:\n",
    "- Write in formal academic English\n",
    "- Use (First Author Last Name, Year) format for citations\n",
    "- For example: \"Smith (2023) demonstrated...\" or \"...has been shown (Smith, 2023)\"\n",
    "- Create smooth transitions between paragraphs\n",
    "- Maintain objective, third-person tone\n",
    "- Length: approximately 1000-1500 words\n",
    "- Do NOT use phrases like \"recent studies show\" without citing specific papers\n",
    "- Ensure every citation corresponds to a paper in the provided list\n",
    "\n",
    "Write a publication-ready Introduction section.\n",
    "\"\"\"\n",
    "    \n",
    "    print(\"ðŸ”„ Introduction ìž‘ì„± ì¤‘ (1-2ë¶„ ì†Œìš”)...\")\n",
    "    \n",
    "    intro_response = client.chat_completions_create(\n",
    "        messages=[{\"role\": \"user\", \"content\": intro_prompt}],\n",
    "        tools=[],\n",
    "        max_turns=1\n",
    "    )\n",
    "    \n",
    "    introduction = intro_response.choices[0].message.content\n",
    "    \n",
    "    print(\"âœ… Introduction ìž‘ì„± ì™„ë£Œ\\n\")\n",
    "    \n",
    "    return introduction\n",
    "\n",
    "print(\"âœ… Introduction ìž‘ì„± ì—ì´ì „íŠ¸ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n",
    "\n",
    "\n",
    "# Agent 2 ì‹¤í–‰\n",
    "introduction_draft = introduction_writer_agent(topic_info, search_result)\n",
    "\n",
    "# í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ìž¥\n",
    "draft_filename = f\"agent2_introduction_draft_{timestamp_agent2}.txt\"\n",
    "with open(draft_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(introduction_draft)\n",
    "\n",
    "print(\"\\n\" + \"=\"*65)\n",
    "print(\"ðŸ’¾ Agent 2 ê²°ê³¼ ì €ìž¥ ì™„ë£Œ\")\n",
    "print(\"=\"*65)\n",
    "print(f\"íŒŒì¼ëª…: {draft_filename}\\n\")\n",
    "\n",
    "# ì „ì²´ ì¶œë ¥\n",
    "print(\"\\n\" + \"=\"*65)\n",
    "print(\"ðŸ“„ Introduction ì´ˆì•ˆ (ì „ì²´)\")\n",
    "print(\"=\"*65 + \"\\n\")\n",
    "print(introduction_draft)\n",
    "\n",
    "print(\"\\n\" + \"=\"*65)\n",
    "print(\"ðŸ“Š í†µê³„\")\n",
    "print(\"=\"*65)\n",
    "print(f\"ì „ì²´ ê¸¸ì´: {len(introduction_draft)} ê¸€ìž\")\n",
    "print(f\"ë‹¨ì–´ ìˆ˜: ì•½ {len(introduction_draft.split())} ë‹¨ì–´\")\n",
    "print(f\"ë¬¸ë‹¨ ìˆ˜: ì•½ {introduction_draft.count(chr(10) + chr(10))} ê°œ\")\n",
    "print(f\"ì €ìž¥ íŒŒì¼: {draft_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 7. Agent 3: ë…¼ë¦¬ ì ê²€ ì—ì´ì „íŠ¸\n",
    "\n",
    "## ðŸ” ë…¼ë¦¬ì  ì¼ê´€ì„± ê²€ì¦\n",
    "\n",
    "ì´ ì—ì´ì „íŠ¸ëŠ” ìž‘ì„±ëœ Introductionì´ ë©”ì¸ í† í”½ê³¼ ë…¼ë¦¬ì ìœ¼ë¡œ ì¼ê´€ì„±ì´ ìžˆëŠ”ì§€ ì ê²€í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ìž‘ë™ ë°©ì‹:\n",
    "\n",
    "#### **1. ë¬¸ìž¥ ë‹¨ìœ„ ë¶„ì„**\n",
    "- Introductionì„ ê°œë³„ ë¬¸ìž¥ìœ¼ë¡œ ë¶„ë¦¬\n",
    "- ê° ë¬¸ìž¥ì´ ë©”ì¸ í† í”½ê³¼ ì–¼ë§ˆë‚˜ ê´€ë ¨ìžˆëŠ”ì§€ í‰ê°€\n",
    "\n",
    "#### **2. ì—°ê´€ì„± ì ìˆ˜ ë¶€ì—¬** (0-10ì )\n",
    "- **0-3ì **: ì•½í•˜ê²Œ ê´€ë ¨ë˜ì—ˆê±°ë‚˜ ì£¼ì œì—ì„œ ë²—ì–´ë‚¨\n",
    "- **4-6ì **: ì¤‘ê°„ ì •ë„ ê´€ë ¨\n",
    "- **7-10ì **: ê°•í•˜ê²Œ ê´€ë ¨\n",
    "\n",
    "#### **3. ë¬¸ì œ ë¬¸ìž¥ ì‹ë³„**\n",
    "- ìž„ê³„ê°’(ê¸°ë³¸ 6ì ) ì´í•˜ì˜ ë¬¸ìž¥ì„ ìžë™ ê°ì§€\n",
    "- ê° ë¬¸ì œ ë¬¸ìž¥ì— ëŒ€í•´:\n",
    "  - ì™œ ì—°ê´€ì„±ì´ ë‚®ì€ê°€?\n",
    "  - ì–´ë–»ê²Œ ê°œì„ í•  ìˆ˜ ìžˆëŠ”ê°€?\n",
    "  - ì‚­ì œ ë˜ëŠ” ìˆ˜ì •ì´ í•„ìš”í•œê°€?\n",
    "\n",
    "### ìž„ê³„ê°’ ì„¤ì •:\n",
    "- `threshold = 0.6` (ê¸°ë³¸ê°’): 6ì  ì´í•˜ ë¬¸ìž¥ì„ ë¬¸ì œë¡œ í‘œì‹œ\n",
    "- ë” ì—„ê²©í•œ ê²€ì‚¬: `threshold = 0.7`\n",
    "- ë” ê´€ëŒ€í•œ ê²€ì‚¬: `threshold = 0.5`\n",
    "\n",
    "**ì‹¤í–‰ ë°©ë²•:**\n",
    "1. Agent 2ê°€ ë¨¼ì € ì‹¤í–‰ë˜ì–´ ìžˆì–´ì•¼ í•©ë‹ˆë‹¤\n",
    "2. í•„ìš”ì‹œ `threshold` ê°’ì„ ì¡°ì •í•˜ì„¸ìš”\n",
    "3. ì‹¤í–‰í•˜ë©´ ë…¼ë¦¬ ì ê²€ ë³´ê³ ì„œê°€ ìƒì„±ë©ë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë…¼ë¦¬ ì ê²€ ì—ì´ì „íŠ¸ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "def logic_checker_agent(\n",
    "    topic_info: Dict[str, Any],\n",
    "    introduction: str,\n",
    "    threshold: float = 0.6\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    ë…¼ë¦¬ ì ê²€ ì—ì´ì „íŠ¸: í† í”½ê³¼ ë¬¸ìž¥ ê°„ ì—°ê´€ì„± ì ê²€\n",
    "    \n",
    "    Args:\n",
    "        topic_info (dict): í† í”½ ì •ì˜ ê²°ê³¼\n",
    "        introduction (str): ìž‘ì„±ëœ Introduction\n",
    "        threshold (float): ì—°ê´€ì„± ìž„ê³„ê°’ (0-1)\n",
    "    \n",
    "    Returns:\n",
    "        dict: ì ê²€ ê²°ê³¼ ë° ê²½ê³  ì‚¬í•­\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ðŸ” ë…¼ë¦¬ ì ê²€ ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘...\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    logic_prompt = f\"\"\"\n",
    "You are a research logic analyzer.\n",
    "\n",
    "Main Research Topic:\n",
    "{topic_info['structured_topic']}\n",
    "\n",
    "Introduction Text:\n",
    "{introduction}\n",
    "\n",
    "Your task:\n",
    "1. Split the introduction into individual sentences\n",
    "2. For each sentence, assess its relevance to the main research topic\n",
    "3. Assign a relevance score (0-10) where:\n",
    "   - 0-3: Weakly related or off-topic\n",
    "   - 4-6: Moderately related\n",
    "   - 7-10: Strongly related\n",
    "\n",
    "4. Identify sentences with score below {threshold * 10}\n",
    "5. For low-scoring sentences, explain:\n",
    "   - Why the relevance is low\n",
    "   - How it could be improved\n",
    "   - Whether it should be removed or rewritten\n",
    "\n",
    "Output format:\n",
    "## Overall Assessment\n",
    "[Brief summary of logical coherence]\n",
    "\n",
    "## Flagged Sentences (score < {threshold * 10})\n",
    "[For each flagged sentence]\n",
    "**Sentence**: [quote the sentence]\n",
    "**Score**: [X/10]\n",
    "**Issue**: [explanation]\n",
    "**Suggestion**: [how to fix]\n",
    "\n",
    "## Recommendations\n",
    "[Overall suggestions for improving logical flow]\n",
    "\"\"\"\n",
    "    \n",
    "    print(\"ðŸ”„ ë…¼ë¦¬ ì ê²€ ì¤‘...\")\n",
    "    \n",
    "    logic_response = client.chat_completions_create(\n",
    "        messages=[{\"role\": \"user\", \"content\": logic_prompt}],\n",
    "        tools=[],\n",
    "        max_turns=1\n",
    "    )\n",
    "    \n",
    "    logic_report = logic_response.choices[0].message.content\n",
    "    \n",
    "    print(\"âœ… ë…¼ë¦¬ ì ê²€ ì™„ë£Œ\\n\")\n",
    "    \n",
    "    return {\n",
    "        \"report\": logic_report,\n",
    "        \"threshold\": threshold\n",
    "    }\n",
    "\n",
    "print(\"âœ… ë…¼ë¦¬ ì ê²€ ì—ì´ì „íŠ¸ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agent 2 ê²°ê³¼ íŒŒì¼ ë¡œë“œ: agent2_introduction_draft_20251104_013725.txt\n",
      "\n",
      "\n",
      "============================================================\n",
      "ðŸ” ë…¼ë¦¬ ì ê²€ ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘...\n",
      "============================================================\n",
      "\n",
      "ðŸ”„ ë…¼ë¦¬ ì ê²€ ì¤‘...\n",
      "âœ… ë…¼ë¦¬ ì ê²€ ì™„ë£Œ\n",
      "\n",
      "\n",
      "=================================================================\n",
      "ðŸ’¾ Agent 3 ê²°ê³¼ ì €ìž¥ ì™„ë£Œ\n",
      "=================================================================\n",
      "íŒŒì¼ëª…: agent3_logic_report_20251104_105032.txt\n",
      "\n",
      "\n",
      "=================================================================\n",
      "ðŸ“‹ ë…¼ë¦¬ ì ê²€ ë³´ê³ ì„œ (ì „ì²´)\n",
      "=================================================================\n",
      "\n",
      "## Overall Assessment\n",
      "The introduction provides a comprehensive overview of the research focus on the Superior Parietal Cortex (SPC) and its role in working memory, particularly in the context of using Transcranial Magnetic Stimulation (TMS) as a research method. The text is highly relevant to the main research topic, clearly outlining the rationale, current research trends, research gaps, and the need for the current study. There is a logical progression from explaining the role of SPC, the application of TMS, to identifying the specific research gap and the need for the study, maintaining coherence and alignment with the research objectives.\n",
      "\n",
      "## Flagged Sentences (score < 7.0)\n",
      "\n",
      "**Sentence**: \"The intricate dynamics between neural circuits in the SPC and their role in memory retention and attentional control continue to captivate neuroscience researchers seeking to delineate the brain's complex functions.\"\n",
      "**Score**: 6/10\n",
      "**Issue**: This sentence is somewhat generic and broad, as it talks about neuroscience researchers without directly linking it to the specific research context of the study.\n",
      "**Suggestion**: To improve relevance, the sentence could specifically mention how understanding these dynamics aids in the exploration of the causal pathways between supra-modal memory and SPC activity within working memory contexts.\n",
      "\n",
      "**Sentence**: \"For instance, Liu et al. (2024) demonstrated that high-frequency repetitive TMS (rTMS) has broad ameliorating effects on working memory among stroke patients, suggesting potential therapeutic applications.\"\n",
      "**Score**: 5/10\n",
      "**Issue**: The mention of stroke patients and therapeutic applications diverts from the main research topic, which is focused on causal investigation rather than therapeutic applications.\n",
      "**Suggestion**: The sentence could be reframed to emphasize the methodological implications of using rTMS to understand working memory rather than the therapeutic potential in stroke patients, thereby aligning closer to the central theme.\n",
      "\n",
      "**Sentence**: \"Similarly, studies by Arciniega et al. (2018) found that frontoparietal transcranial Direct Current Stimulation (tDCS) could benefit visual working memory in older adults, highlighting age-related considerations in memory retention.\"\n",
      "**Score**: 4/10\n",
      "**Issue**: This sentence introduces another brain stimulation technique and different demographic (older adults) without directly linking it back to the primary focus of the SPC and supra-modal memory.\n",
      "**Suggestion**: Remove this sentence or refocus it to establish a comparative analysis of TMS versus tDCS in researching the SPC's role in working memory, directly linking it to supra-modal memory processes.\n",
      "\n",
      "**Sentence**: \"This growing body of research illustrates a thematic focus on understanding the interactions between brain stimulation, neural connectivity, and cognitive function.\"\n",
      "**Score**: 6/10\n",
      "**Issue**: The sentence is a broad statement, not specifically focused on the concerns of the SPC, supra-modal memory, or the role of TMS in those processes.\n",
      "**Suggestion**: Tie this statement specifically to how these interactions contribute directly to understanding the SPC's functions in managing distractors in working memory contexts.\n",
      "\n",
      "## Recommendations\n",
      "The introduction is generally well-structured and relevant to the research aim, yet certain sentences could be refined for tighter alignment to the main research topic. To improve logical flow:\n",
      "\n",
      "1. Integrate specific connections or linkages to the main research topic in sentences that seem more general or broad.\n",
      "2. Maintain focus on the primary research tools and objectives, referencing other methodologies or contexts only as they directly apply to understanding the SPC's role and function within the study's scope.\n",
      "3. Remove or revise sentences that introduce tangential topics or demographics unless explicitly tied back to the research focus on the importance of SPC activity and TMS effects on supra-modal memory.\n",
      "\n",
      "=================================================================\n",
      "ðŸ“Š ì •ë³´\n",
      "=================================================================\n",
      "ìž…ë ¥ íŒŒì¼: agent2_introduction_draft_20251104_013725.txt\n",
      "ì €ìž¥ íŒŒì¼: agent3_logic_report_20251104_105032.txt\n",
      "ìž„ê³„ê°’: 0.7\n"
     ]
    }
   ],
   "source": [
    "# ì—°ê´€ì„± ìž„ê³„ê°’ ì„¤ì • (0.0 - 1.0)\n",
    "threshold = 0.7\n",
    "\n",
    "# Agent 0 ê²°ê³¼ í™•ì¸ (topic_info)\n",
    "try:\n",
    "    if 'topic_info' not in locals() or topic_info is None:\n",
    "        raise NameError(\"topic_info not defined\")\n",
    "except NameError:\n",
    "    print(\"âš ï¸ topic_infoê°€ ì •ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Agent 0 ê²°ê³¼ íŒŒì¼ì„ ì°¾ëŠ” ì¤‘...\\n\")\n",
    "    import glob\n",
    "    topic_files = glob.glob(\"agent0_topic_definition_*.txt\")\n",
    "    if topic_files:\n",
    "        topic_files.sort(reverse=True)\n",
    "        with open(topic_files[0], \"r\", encoding=\"utf-8\") as f:\n",
    "            content = f.read()\n",
    "        parts = content.split(\"=\"*65)\n",
    "        if len(parts) >= 2:\n",
    "            user_input_part = parts[0].replace(\"User Input:\", \"\").strip()\n",
    "            structured_part = parts[2].strip() if len(parts) > 2 else parts[1].strip()\n",
    "            structured_part = structured_part.replace(\"Structured Topic Information:\", \"\").strip()\n",
    "            topic_info = {\n",
    "                \"user_input\": user_input_part,\n",
    "                \"structured_topic\": structured_part\n",
    "            }\n",
    "            print(f\"âœ… Agent 0 ê²°ê³¼ ë¡œë“œ: {topic_files[0]}\")\n",
    "    else:\n",
    "        raise FileNotFoundError(\"Agent 0 ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# Agent 2ì˜ ê²°ê³¼ íŒŒì¼ ì½ê¸°\n",
    "try:\n",
    "    with open(draft_filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        introduction_draft_from_file = f.read()\n",
    "    print(f\"âœ… Agent 2 ê²°ê³¼ íŒŒì¼ ë¡œë“œ: {draft_filename}\\n\")\n",
    "except NameError:\n",
    "    print(\"âš ï¸ draft_filenameì´ ì •ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Agent 2ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.\\n\")\n",
    "    # ê°€ìž¥ ìµœê·¼ íŒŒì¼ ì°¾ê¸°\n",
    "    import glob\n",
    "    draft_files = glob.glob(\"agent2_introduction_draft_*.txt\")\n",
    "    if draft_files:\n",
    "        draft_files.sort(reverse=True)\n",
    "        draft_filename = draft_files[0]\n",
    "        with open(draft_filename, \"r\", encoding=\"utf-8\") as f:\n",
    "            introduction_draft_from_file = f.read()\n",
    "        print(f\"âœ… ê°€ìž¥ ìµœê·¼ Agent 2 ê²°ê³¼ íŒŒì¼ ë¡œë“œ: {draft_filename}\\n\")\n",
    "    else:\n",
    "        raise FileNotFoundError(\"Agent 2 ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Agent 2ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
    "\n",
    "# Agent 3 ì‹¤í–‰\n",
    "logic_report = logic_checker_agent(topic_info, introduction_draft_from_file, threshold)\n",
    "\n",
    "# íƒ€ìž„ìŠ¤íƒ¬í”„ ìƒì„±\n",
    "timestamp_agent3 = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ìž¥\n",
    "logic_filename = f\"agent3_logic_report_{timestamp_agent3}.txt\"\n",
    "with open(logic_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(logic_report[\"report\"])\n",
    "\n",
    "print(\"\\n\" + \"=\"*65)\n",
    "print(\"ðŸ’¾ Agent 3 ê²°ê³¼ ì €ìž¥ ì™„ë£Œ\")\n",
    "print(\"=\"*65)\n",
    "print(f\"íŒŒì¼ëª…: {logic_filename}\\n\")\n",
    "\n",
    "# ë³´ê³ ì„œ ì¶œë ¥\n",
    "print(\"\\n\" + \"=\"*65)\n",
    "print(\"ðŸ“‹ ë…¼ë¦¬ ì ê²€ ë³´ê³ ì„œ (ì „ì²´)\")\n",
    "print(\"=\"*65 + \"\\n\")\n",
    "print(logic_report[\"report\"])\n",
    "\n",
    "print(\"\\n\" + \"=\"*65)\n",
    "print(\"ðŸ“Š ì •ë³´\")\n",
    "print(\"=\"*65)\n",
    "print(f\"ìž…ë ¥ íŒŒì¼: {draft_filename}\")\n",
    "print(f\"ì €ìž¥ íŒŒì¼: {logic_filename}\")\n",
    "print(f\"ìž„ê³„ê°’: {threshold}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 7.5. Agent 3.5: ë…¼ë¦¬ ì ê²€ ê¸°ë°˜ Introduction ìž¬ìž‘ì„± ì—ì´ì „íŠ¸\n",
    "\n",
    "## âœï¸ ë…¼ë¦¬ì  ì¼ê´€ì„± ê°œì„ \n",
    "\n",
    "ì´ ì—ì´ì „íŠ¸ëŠ” Agent 3ì˜ ë…¼ë¦¬ ì ê²€ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ Introductionì„ ë‹¤ì‹œ ìž‘ì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ìž‘ë™ ë°©ì‹:\n",
    "\n",
    "#### **1. ìž…ë ¥ ë°ì´í„°**\n",
    "- **Agent 2 ì´ˆì•ˆ**: ì›ë³¸ Introduction í…ìŠ¤íŠ¸\n",
    "- **Agent 3 ë³´ê³ ì„œ**: ë…¼ë¦¬ ì ê²€ ê²°ê³¼ ë° ë¬¸ì œì \n",
    "\n",
    "#### **2. ê°œì„  ìž‘ì—…**\n",
    "- ìž„ê³„ê°’ ì´í•˜ ë¬¸ìž¥ ì‹ë³„ ë° ê°œì„ \n",
    "- ì£¼ì œì™€ ê´€ë ¨ì„±ì´ ë‚®ì€ ë¬¸ìž¥ ìˆ˜ì • ë˜ëŠ” ì œê±°\n",
    "- ë…¼ë¦¬ íë¦„ ê°œì„ \n",
    "- ë¬¸ë‹¨ ê°„ ì—°ê²° ê°•í™”\n",
    "\n",
    "#### **3. ìž¬ìž‘ì„± ì „ëžµ**\n",
    "- **ì ìˆ˜ 0-4ì **: ì‚­ì œ ë˜ëŠ” ì™„ì „ížˆ ìž¬ìž‘ì„±\n",
    "- **ì ìˆ˜ 4-6ì **: ì£¼ì œì™€ì˜ ì—°ê´€ì„± ê°•í™”\n",
    "- **ì ìˆ˜ 7-10ì **: ìœ ì§€ (í•„ìš”ì‹œ ë¯¸ì„¸ ì¡°ì •)\n",
    "\n",
    "#### **4. ì¶œë ¥**\n",
    "- ë…¼ë¦¬ì ìœ¼ë¡œ ê°œì„ ëœ Introduction\n",
    "- ëª¨ë“  ë¬¸ìž¥ì´ ë©”ì¸ í† í”½ê³¼ ëª…í™•ížˆ ì—°ê²°\n",
    "- ìžì—°ìŠ¤ëŸ¬ìš´ íë¦„ ìœ ì§€\n",
    "\n",
    "### ì¶œë ¥:\n",
    "- ë…¼ë¦¬ì ìœ¼ë¡œ ê°œì„ ëœ Introduction í…ìŠ¤íŠ¸\n",
    "- íŒŒì¼ ì €ìž¥: `agent3.5_logic_revised_[timestamp].txt`\n",
    "- Agent 4 (User Integration) ë˜ëŠ” Agent 5 (Style Checker)ì˜ ìž…ë ¥ìœ¼ë¡œ ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë…¼ë¦¬ ì ê²€ ê¸°ë°˜ ìž¬ìž‘ì„± ì—ì´ì „íŠ¸ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "def logic_based_rewriter_agent(\n",
    "    introduction_draft: str,\n",
    "    logic_report: Dict[str, Any]\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    ë…¼ë¦¬ ì ê²€ ê¸°ë°˜ Introduction ìž¬ìž‘ì„± ì—ì´ì „íŠ¸\n",
    "    \n",
    "    Args:\n",
    "        introduction_draft (str): Agent 2ì˜ ì´ˆì•ˆ\n",
    "        logic_report (dict): Agent 3ì˜ ë…¼ë¦¬ ì ê²€ ê²°ê³¼\n",
    "    \n",
    "    Returns:\n",
    "        str: ë…¼ë¦¬ì ìœ¼ë¡œ ê°œì„ ëœ Introduction\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*65)\n",
    "    print(\"ðŸ”„ ë…¼ë¦¬ ì ê²€ ê¸°ë°˜ ìž¬ìž‘ì„± ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘...\")\n",
    "    print(\"=\"*65 + \"\\n\")\n",
    "    \n",
    "    rewrite_prompt = f\"\"\"\n",
    "You are an expert academic editor specializing in logical coherence and argumentation.\n",
    "\n",
    "Original Introduction:\n",
    "{introduction_draft}\n",
    "\n",
    "Logic Check Report:\n",
    "{logic_report['report']}\n",
    "\n",
    "Your task:\n",
    "Rewrite the Introduction to address ALL issues identified in the Logic Check Report.\n",
    "\n",
    "Specific instructions:\n",
    "\n",
    "1. **Identify problematic sentences**:\n",
    "   - Sentences with low relevance scores (below threshold)\n",
    "   - Sentences flagged in the report\n",
    "   - Sentences that deviate from the main research topic\n",
    "\n",
    "2. **Apply corrections**:\n",
    "   - Score 0-5: Remove or completely rewrite to align with the topic\n",
    "   - Score 6-7: Strengthen connection to the main research topic\n",
    "   - Score 8-10: Keep but refine if necessary\n",
    "\n",
    "3. **Improve logical flow**:\n",
    "   - Ensure smooth transitions between ideas\n",
    "   - Maintain clear progression from broad context to specific research gap\n",
    "   - Strengthen connections between paragraphs\n",
    "\n",
    "4. **Maintain structure**:\n",
    "   - Keep the 4-part structure: (1) Topic introduction, (2) Current research, (3) Research gap, (4) Study rationale\n",
    "   - Preserve all valid citations (Author, Year)\n",
    "   - Keep the academic tone and formal language\n",
    "\n",
    "5. **Focus areas**:\n",
    "   - Remove tangential discussions\n",
    "   - Eliminate redundancy\n",
    "   - Clarify vague statements\n",
    "   - Ensure every sentence contributes to the argument\n",
    "\n",
    "Output requirements:\n",
    "- Complete, coherent Introduction text\n",
    "- All logical issues from the report must be addressed\n",
    "- Maintain citation format: (Author, Year)\n",
    "- Length: approximately 1000-1500 words\n",
    "- Publication-ready quality\n",
    "\n",
    "Write the improved Introduction now.\n",
    "\"\"\"\n",
    "    \n",
    "    print(\"ðŸ”„ ë…¼ë¦¬ ì ê²€ í”¼ë“œë°± ì ìš© ë° ìž¬ìž‘ì„± ì¤‘ (1-2ë¶„ ì†Œìš”)...\")\n",
    "    \n",
    "    rewrite_response = client.chat_completions_create(\n",
    "        messages=[{\"role\": \"user\", \"content\": rewrite_prompt}],\n",
    "        tools=[],\n",
    "        max_turns=1\n",
    "    )\n",
    "    \n",
    "    revised_introduction = rewrite_response.choices[0].message.content\n",
    "    \n",
    "    print(\"âœ… ë…¼ë¦¬ ì ê²€ ê¸°ë°˜ ìž¬ìž‘ì„± ì™„ë£Œ\\n\")\n",
    "    \n",
    "    return revised_introduction\n",
    "\n",
    "print(\"âœ… ë…¼ë¦¬ ì ê²€ ê¸°ë°˜ ìž¬ìž‘ì„± ì—ì´ì „íŠ¸ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Agent 3.5 ì‹¤í–‰í•˜ê¸°\n",
    "\n",
    "ì•„ëž˜ ì…€ì„ ì‹¤í–‰í•˜ì—¬ ë…¼ë¦¬ ì ê²€ í”¼ë“œë°±ì„ ë°˜ì˜í•œ Introductionì„ ìž¬ìž‘ì„±í•˜ì„¸ìš”.\n",
    "\n",
    "**ì†Œìš” ì‹œê°„:** ì•½ 1-2ë¶„\n",
    "\n",
    "**ê²°ê³¼:**\n",
    "- íŒŒì¼ë¡œ ìžë™ ì €ìž¥: `agent3.5_logic_revised_[timestamp].txt`\n",
    "- ì „ì²´ í…ìŠ¤íŠ¸ ì¶œë ¥\n",
    "\n",
    "**ì‹¤í–‰ ë°©ë²•:**\n",
    "1. Agent 2ì™€ Agent 3ì´ ë¨¼ì € ì‹¤í–‰ë˜ì–´ ìžˆì–´ì•¼ í•©ë‹ˆë‹¤\n",
    "2. ì•„ëž˜ ì…€ì„ ì‹¤í–‰í•˜ë©´ ìžë™ìœ¼ë¡œ íŒŒì¼ì„ ì°¾ì•„ ë¡œë“œí•©ë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agent 2 ê²°ê³¼ ë¡œë“œ: agent2_introduction_draft_20251104_013725.txt\n",
      "âœ… Agent 3 ê²°ê³¼ ë¡œë“œ: agent3_logic_report_20251104_105032.txt\n",
      "\n",
      "\n",
      "=================================================================\n",
      "ðŸ”„ ë…¼ë¦¬ ì ê²€ ê¸°ë°˜ ìž¬ìž‘ì„± ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘...\n",
      "=================================================================\n",
      "\n",
      "ðŸ”„ ë…¼ë¦¬ ì ê²€ í”¼ë“œë°± ì ìš© ë° ìž¬ìž‘ì„± ì¤‘ (1-2ë¶„ ì†Œìš”)...\n",
      "âœ… ë…¼ë¦¬ ì ê²€ ê¸°ë°˜ ìž¬ìž‘ì„± ì™„ë£Œ\n",
      "\n",
      "\n",
      "=================================================================\n",
      "ðŸ’¾ Agent 3.5 ê²°ê³¼ ì €ìž¥ ì™„ë£Œ\n",
      "=================================================================\n",
      "íŒŒì¼ëª…: agent3.5_logic_revised_20251104_105313.txt\n",
      "\n",
      "\n",
      "=================================================================\n",
      "ðŸ“„ ë…¼ë¦¬ ì ê²€ ê¸°ë°˜ ê°œì„ ëœ Introduction (ì „ì²´)\n",
      "=================================================================\n",
      "\n",
      "**Introduction to the Main Topic**\n",
      "\n",
      "The Superior Parietal Cortex (SPC) is a critical region of the human brain involved in multiple cognitive functions, particularly focusing on working memory and sensory integration. Located in the posterior part of the brain, the SPC plays an essential role in modulating attention and supporting the retention of information across different sensory modalities, a process referred to as supra-modal memory. Comprehending the mechanisms of this process is vital, as working memory forms the foundation for higher-order cognitive functions such as problem-solving and planning. Recent advancements in neuroscience are increasingly centered on elucidating the interactions between the SPC's neural circuits and their role in memory retention and attentional control, enhancing our understanding of the brain's complex functionality.\n",
      "\n",
      "Transcranial Magnetic Stimulation (TMS) has become a significant investigative tool in exploring the causal relationships between neural activity and cognitive processes. This non-invasive technique involves delivering magnetic pulses to specific brain regions, allowing researchers to observe changes in neural activity and, subsequently, cognitive performance. In the context of working memory, TMS has been employed to explore its effects on tasks that require retaining and manipulating information. By analyzing alterations in cognitive performance due to TMS application, such as those that affect the SPC, researchers gain insights into how targeted disruptions in neural activity can influence working memory. Understanding the SPCâ€™s role in managing distractions and cognitive load presents a valuable opportunity for enhancing our comprehension of cognitive resilience in dynamic environments.\n",
      "\n",
      "**Current Research Trends**\n",
      "\n",
      "Cognitive neuroscience research is increasingly focused on the interplay between brain stimulation techniques and cognitive processes, with particular attention on the SPCâ€™s role. For instance, Liu et al. (2024) explored the methodological implications of high-frequency repetitive TMS (rTMS) in studying working memory, highlighting its broader effects on specific brain functions. Such research underscores TMS's potential in revealing the underlying processes that govern working memory, irrespective of any therapeutic applications it may have for conditions like stroke.\n",
      "\n",
      "Further investigations into the functional connectivity of the SPC are yielding intriguing insights. Hwang et al. (2020) illustrated that the intraparietal sulcusâ€”a part of the parietal cortexâ€”modulates task-evoked functional connectivity, influencing working memory performance. Such findings emphasize the SPC's importance in processing information across varying cognitive demands, further broadening our understanding of the brainâ€™s adaptability in different contexts. Additionally, Romei et al. (2011) emphasized the connection between specific brain frequencies and cognitive processing through rhythmic TMS over the parietal cortex, which highlights the SPC's involvement in perceptual aspects of cognition.\n",
      "\n",
      "Research focused on TMS applications also illuminates the specific neural activities engaged during working memory tasks. Oh and Leung (2010) examined the cortical underpinnings involved in processing visual representations, emphasizing the importance of selective attention in memory retention. This growing body of work accentuates the thematic focus on understanding brain stimulation's relationships with neural connectivity and cognitive functioning, directly tied to the SPC's role in managing working memory amidst distractions.\n",
      "\n",
      "**Research Gap**\n",
      "\n",
      "Despite significant advances in recognizing the SPCâ€™s role in cognitive functions, several key questions remain unanswered. Specifically, the precise causal pathways linking supra-modal memory retention to SPC activity, especially in environments filled with distractors, require further exploration. Current studies often examine isolated elements of working memory or operate under uniform experimental conditions, which do not adequately reflect the multifaceted interference and cognitive challenges encountered in real-world environments. While TMS offers an effective means of probing these neural circuits, there is still limited consensus on the variability of its effects across different cognitive tasks and situations.\n",
      "\n",
      "This gap becomes particularly relevant when considering therapeutic approaches for cognitive impairments. Proskovec et al. (2018) identified that oscillatory dynamics in the prefrontal and superior temporal cortices correlate with spatial working memory performance. However, the mechanisms through which the SPC influences these dynamics have not been sufficiently investigated. Addressing these limitations is essential for developing sophisticated cognitive function models and more effective targeted interventions.\n",
      "\n",
      "**Need for the Current Study**\n",
      "\n",
      "This study intends to address the identified gaps by investigating the causal relationship between supra-modal memory retention and SPC activity through the targeted application of TMS. By specifically examining working memory performance in conditions both with and without distractors, this research seeks to elucidate the complex interactions within the SPC and its influence on cognitive resilience. TMS provides a unique opportunity to causally examine these relationships, thereby offering valuable insights into both the brain's normative functioning and potential dysregulation observed in clinical populations.\n",
      "\n",
      "The study aims to contribute to a more comprehensive understanding of the SPC's role in cognitive processing, bridging the gap between theoretical neuroscience and practical applications. By highlighting factors that influence working memory in contexts with cognitive challenges, this research may inform strategies to enhance cognitive health and performance across diverse populations. Consequently, the study positions itself at the forefront of innovative interventions aimed at optimizing brain function.\n",
      "\n",
      "In addressing these objectives, our research endeavors not only to expand theoretical understanding within cognitive neuroscience but also to impact the methodologies employed in assessing and supporting cognitive functions in real-world scenarios. The findings promise to deepen the scientific communityâ€™s understanding of complex neural processes, marking this work as a significant contribution to the ongoing pursuit of cognitive enhancement and rehabilitation.\n",
      "\n",
      "=================================================================\n",
      "ðŸ“Š í†µê³„\n",
      "=================================================================\n",
      "ì „ì²´ ê¸¸ì´: 6532 ê¸€ìž\n",
      "ë‹¨ì–´ ìˆ˜: ì•½ 859 ë‹¨ì–´\n",
      "ìž…ë ¥ íŒŒì¼ (ì´ˆì•ˆ): agent2_introduction_draft_20251104_013725.txt\n",
      "ìž…ë ¥ íŒŒì¼ (ë…¼ë¦¬ ì ê²€): agent3_logic_report_20251104_105032.txt\n",
      "ì €ìž¥ íŒŒì¼: agent3.5_logic_revised_20251104_105313.txt\n"
     ]
    }
   ],
   "source": [
    "# Agent 2 ì´ˆì•ˆ íŒŒì¼ ì½ê¸°\n",
    "try:\n",
    "    with open(draft_filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        introduction_draft_for_rewrite = f.read()\n",
    "    print(f\"âœ… Agent 2 ê²°ê³¼ ë¡œë“œ: {draft_filename}\")\n",
    "except (NameError, FileNotFoundError):\n",
    "    print(\"âš ï¸ Agent 2 ê²°ê³¼ íŒŒì¼ì„ ì°¾ëŠ” ì¤‘...\\n\")\n",
    "    import glob\n",
    "    draft_files = glob.glob(\"agent2_introduction_draft_*.txt\")\n",
    "    if draft_files:\n",
    "        draft_files.sort(reverse=True)\n",
    "        draft_filename = draft_files[0]\n",
    "        with open(draft_filename, \"r\", encoding=\"utf-8\") as f:\n",
    "            introduction_draft_for_rewrite = f.read()\n",
    "        print(f\"âœ… ê°€ìž¥ ìµœê·¼ Agent 2 ê²°ê³¼ ë¡œë“œ: {draft_filename}\")\n",
    "    else:\n",
    "        raise FileNotFoundError(\"Agent 2 ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# Agent 3 ë…¼ë¦¬ ì ê²€ ë³´ê³ ì„œ ì½ê¸°\n",
    "try:\n",
    "    with open(logic_filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        logic_report_for_rewrite = {\"report\": f.read()}\n",
    "    print(f\"âœ… Agent 3 ê²°ê³¼ ë¡œë“œ: {logic_filename}\")\n",
    "except (NameError, FileNotFoundError):\n",
    "    print(\"âš ï¸ Agent 3 ê²°ê³¼ íŒŒì¼ì„ ì°¾ëŠ” ì¤‘...\\n\")\n",
    "    import glob\n",
    "    logic_files = glob.glob(\"agent3_logic_report_*.txt\")\n",
    "    if logic_files:\n",
    "        logic_files.sort(reverse=True)\n",
    "        logic_filename = logic_files[0]\n",
    "        with open(logic_filename, \"r\", encoding=\"utf-8\") as f:\n",
    "            logic_report_for_rewrite = {\"report\": f.read()}\n",
    "        print(f\"âœ… ê°€ìž¥ ìµœê·¼ Agent 3 ê²°ê³¼ ë¡œë“œ: {logic_filename}\")\n",
    "    else:\n",
    "        raise FileNotFoundError(\"Agent 3 ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Agent 3ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Agent 3.5 ì‹¤í–‰\n",
    "logic_revised_introduction = logic_based_rewriter_agent(\n",
    "    introduction_draft_for_rewrite,\n",
    "    logic_report_for_rewrite\n",
    ")\n",
    "\n",
    "# íƒ€ìž„ìŠ¤íƒ¬í”„ ìƒì„±\n",
    "timestamp_agent35 = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ìž¥\n",
    "logic_revised_filename = f\"agent3.5_logic_revised_{timestamp_agent35}.txt\"\n",
    "with open(logic_revised_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(logic_revised_introduction)\n",
    "\n",
    "print(\"\\n\" + \"=\"*65)\n",
    "print(\"ðŸ’¾ Agent 3.5 ê²°ê³¼ ì €ìž¥ ì™„ë£Œ\")\n",
    "print(\"=\"*65)\n",
    "print(f\"íŒŒì¼ëª…: {logic_revised_filename}\\n\")\n",
    "\n",
    "# ì „ì²´ ì¶œë ¥\n",
    "print(\"\\n\" + \"=\"*65)\n",
    "print(\"ðŸ“„ ë…¼ë¦¬ ì ê²€ ê¸°ë°˜ ê°œì„ ëœ Introduction (ì „ì²´)\")\n",
    "print(\"=\"*65 + \"\\n\")\n",
    "print(logic_revised_introduction)\n",
    "\n",
    "print(\"\\n\" + \"=\"*65)\n",
    "print(\"ðŸ“Š í†µê³„\")\n",
    "print(\"=\"*65)\n",
    "print(f\"ì „ì²´ ê¸¸ì´: {len(logic_revised_introduction)} ê¸€ìž\")\n",
    "print(f\"ë‹¨ì–´ ìˆ˜: ì•½ {len(logic_revised_introduction.split())} ë‹¨ì–´\")\n",
    "print(f\"ìž…ë ¥ íŒŒì¼ (ì´ˆì•ˆ): {draft_filename}\")\n",
    "print(f\"ìž…ë ¥ íŒŒì¼ (ë…¼ë¦¬ ì ê²€): {logic_filename}\")\n",
    "print(f\"ì €ìž¥ íŒŒì¼: {logic_revised_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 8. Agent 4: ì‚¬ìš©ìž-íŒŒì´í”„ë¼ì¸ í†µí•© ì—ì´ì „íŠ¸\n",
    "\n",
    "## ðŸ”— ì‚¬ìš©ìž ìž‘ì„±ë³¸ê³¼ ìžë™ ìƒì„± ê²°ê³¼ í†µí•©\n",
    "\n",
    "ì´ ì—ì´ì „íŠ¸ëŠ” **ì‚¬ìš©ìžê°€ ì§ì ‘ ìž‘ì„±í•œ Introduction**ê³¼ **íŒŒì´í”„ë¼ì¸ì´ ìƒì„±í•œ Introduction**ì„ í†µí•©í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ìž‘ë™ ë°©ì‹:\n",
    "\n",
    "#### **ìž…ë ¥:**\n",
    "1. **ì‚¬ìš©ìž ìž‘ì„± Introduction** (íŒŒì¼ ê²½ë¡œ ì§€ì • ë˜ëŠ” ì˜ˆì‹œ ì‚¬ìš©)\n",
    "2. **Agent 3.5 ë…¼ë¦¬ ê°œì„  ê²°ê³¼** (`agent3.5_logic_revised_*.txt`)\n",
    "3. **Agent 1 ê²€ìƒ‰ ê²°ê³¼** (ì„ íƒì‚¬í•­, ì¶”ê°€ ì¸ìš©ì„ ìœ„í•´)\n",
    "\n",
    "#### **í†µí•© ê³¼ì •:**\n",
    "1. **ì‚¬ìš©ìž í…ìŠ¤íŠ¸ ë¶„ì„**\n",
    "   - ë…¼ë¦¬ êµ¬ì¡° íŒŒì•…\n",
    "   - í•µì‹¬ ì£¼ìž¥ ì‹ë³„\n",
    "   - ë¬¸ë‹¨ë³„ ì£¼ì œ íŒŒì•…\n",
    "\n",
    "2. **íŒŒì´í”„ë¼ì¸ ê²°ê³¼ ì°¸ì¡°**\n",
    "   - ì‚¬ìš©ìž ì£¼ìž¥ê³¼ ë™ë–¨ì–´ì§„ ë‚´ìš© ìˆ˜ì •\n",
    "   - ì‚¬ìš©ìž í…ìŠ¤íŠ¸ì—ì„œ í•„ìš”í•œ ì •ë³´ ë°œì·Œí•˜ì—¬ í™œìš©\n",
    "   - ì ì ˆí•œ ë³´ê°• í¬ì¸íŠ¸ ì‹ë³„\n",
    "\n",
    "3. **ìžì—°ìŠ¤ëŸ½ê²Œ í†µí•©**\n",
    "   - ì‚¬ìš©ìž ë¬¸ìž¥ì— ì¸ìš© ì¶”ê°€\n",
    "   - ì—°êµ¬ ê²°ê³¼ë¡œ ì£¼ìž¥ ë’·ë°›ì¹¨\n",
    "   - ë¬¸ë‹¨ ê°„ ì—°ê²° ê°œì„ \n",
    "   - **ì¤‘ìš”**: ì‚¬ìš©ìžì˜ ì›ëž˜ ì˜ë„ ìœ ì§€\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Agent 4 ì‹¤í–‰í•˜ê¸°\n",
    "\n",
    "ì•„ëž˜ ì…€ì„ ì‹¤í–‰í•˜ì—¬ ì‚¬ìš©ìž ìž‘ì„±ë³¸ê³¼ íŒŒì´í”„ë¼ì¸ ê²°ê³¼ë¥¼ í†µí•©í•˜ì„¸ìš”.\n",
    "Agent 3.5ê¹Œì§€ ì‹¤í–‰ë˜ì–´ ìžˆì–´ì•¼ í•©ë‹ˆë‹¤\n",
    "\n",
    "**ì†Œìš” ì‹œê°„:** ì•½ 1-2ë¶„\n",
    "\n",
    "### ìž…ë ¥ ì„¤ì •:\n",
    "\n",
    "#### **Option 1: ì‚¬ìš©ìž ìž‘ì„± íŒŒì¼ ì‚¬ìš©**\n",
    "```python\n",
    "user_intro_file = \"ê²½ë¡œ/to/your_introduction.txt\"\n",
    "```\n",
    "\n",
    "### ì¶œë ¥:\n",
    "- ì‚¬ìš©ìž ë…¼ë¦¬ + íŒŒì´í”„ë¼ì¸ ì¸ìš©ì´ í†µí•©ëœ Introduction\n",
    "- íŒŒì¼ ì €ìž¥: `agent4_integrated_[timestamp].txt`\n",
    "- í™”ë©´ ì¶œë ¥: ì „ì²´ í…ìŠ¤íŠ¸\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì‚¬ìš©ìž-íŒŒì´í”„ë¼ì¸ í†µí•© ì—ì´ì „íŠ¸ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "def user_pipeline_integrator_agent(\n",
    "    user_introduction: str,\n",
    "    pipeline_introduction: str,\n",
    "    search_result: Dict[str, Any] = None\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    ì‚¬ìš©ìž ìž‘ì„±ë³¸ê³¼ íŒŒì´í”„ë¼ì¸ ê²°ê³¼ í†µí•© ì—ì´ì „íŠ¸\n",
    "    \n",
    "    Args:\n",
    "        user_introduction (str): ì‚¬ìš©ìžê°€ ì§ì ‘ ìž‘ì„±í•œ Introduction\n",
    "        pipeline_introduction (str): íŒŒì´í”„ë¼ì¸ì´ ìƒì„±í•œ Introduction (Agent 3.5 ê²°ê³¼)\n",
    "        search_result (dict): ê²€ìƒ‰ëœ ë…¼ë¬¸ ì •ë³´ (ì„ íƒ)\n",
    "    \n",
    "    Returns:\n",
    "        str: í†µí•©ëœ Introduction\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*65)\n",
    "    print(\"ðŸ”€ ì‚¬ìš©ìž ìž‘ì„±ë³¸-íŒŒì´í”„ë¼ì¸ í†µí•© ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘...\")\n",
    "    print(\"=\"*65 + \"\\n\")\n",
    "    \n",
    "    # ë…¼ë¬¸ ì •ë³´ ì¤€ë¹„\n",
    "    papers_info = \"\"\n",
    "    if search_result and \"papers\" in search_result:\n",
    "        papers_summary = json.dumps(search_result[\"papers\"][:10], indent=2, ensure_ascii=False)\n",
    "        papers_info = f\"\\n\\nAvailable Papers for Citation:\\n{papers_summary}\"\n",
    "    \n",
    "    integration_prompt = f\"\"\"\n",
    "You are an expert academic editor specializing in neuroscience manuscripts.\n",
    "\n",
    "GOAL:\n",
    "Rewrite a publication-ready Introduction that is **based on the user's main ideas and logic**, but **do not preserve full sentences from the user's text**. Treat the user's Introduction only as a source of inspiration for key points, main arguments, and structure.\n",
    "\n",
    "User Introduction (Reference Only):\n",
    "{user_introduction}\n",
    "\n",
    "Pipeline-Generated Introduction (Reference Only - For Supplementary Info):\n",
    "{pipeline_introduction}\n",
    "{papers_info}\n",
    "\n",
    "*RULES:\n",
    "\n",
    "1. **Idea-Based Guidance**\n",
    "   - Extract the main arguments, key points, and overall logic from the user's text.\n",
    "   - Do not copy sentences verbatim.\n",
    "   - Use user's text to guide the narrative, but the final text should be mostly newly composed.\n",
    "\n",
    "2. **Selective Supplementation**\n",
    "   - Integrate pipeline content **only if it reinforces or clarifies the user's ideas**.\n",
    "   - Add relevant citations, examples, or precise terminology where appropriate.\n",
    "   - Discard low-relevance, redundant, or unrelated content.\n",
    "\n",
    "3. **Clarity, Coherence, and Academic Style**\n",
    "   - Ensure smooth flow, logical transitions, and formal journal tone.\n",
    "   - Minor rewording of user points is allowed, but most sentences should be new compositions.\n",
    "   - Avoid abrupt insertions; integrate supplemental content seamlessly.\n",
    "\n",
    "4. **Citation Integration**\n",
    "   - Include citations from the pipeline or search results **only to support userâ€™s key claims**.\n",
    "   - Do not introduce unrelated studies or topics.\n",
    "\n",
    "------\n",
    "\n",
    "OUTPUT:\n",
    "Produce a fully rewritten, coherent, publication-ready Introduction:\n",
    "- ~60% new sentences inspired by user's logic.\n",
    "- ~40% supplemental evidence or citations from pipeline/search results.\n",
    "- Main ideas and narrative flow are guided by the user's text, but the final wording is original.\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    print(\"ðŸ”„ ì‚¬ìš©ìž ìž‘ì„±ë³¸ ê¸°ë°˜ í†µí•© ì¤‘ (1-2ë¶„ ì†Œìš”)...\")\n",
    "    \n",
    "    integration_response = client.chat_completions_create(\n",
    "        messages=[{\"role\": \"user\", \"content\": integration_prompt}],\n",
    "        tools=[],\n",
    "        max_turns=1\n",
    "    )\n",
    "    \n",
    "    integrated_introduction = integration_response.choices[0].message.content\n",
    "    \n",
    "    print(\"âœ… í†µí•© ì™„ë£Œ\\n\")\n",
    "    \n",
    "    return integrated_introduction\n",
    "\n",
    "print(\"âœ… ì‚¬ìš©ìž-íŒŒì´í”„ë¼ì¸ í†µí•© ì—ì´ì „íŠ¸ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì‚¬ìš©ìž ìž‘ì„± Introduction ë¡œë“œ: /Users/he2ryoo/Documents/GitHub/ejung-ryoo/HW6/user_introduction/revised_introduction.txt\n",
      "\n",
      "âœ… Agent 3.5 ê²°ê³¼ ë¡œë“œ: agent3.5_logic_revised_20251104_105313.txt\n",
      "âœ… Agent 1 ê²€ìƒ‰ ê²°ê³¼ ë¡œë“œ: papers_search_20251104_013555.json\n",
      "\n",
      "\n",
      "=================================================================\n",
      "ðŸ”€ ì‚¬ìš©ìž ìž‘ì„±ë³¸-íŒŒì´í”„ë¼ì¸ í†µí•© ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘...\n",
      "=================================================================\n",
      "\n",
      "ðŸ”„ ì‚¬ìš©ìž ìž‘ì„±ë³¸ ê¸°ë°˜ í†µí•© ì¤‘ (1-2ë¶„ ì†Œìš”)...\n",
      "âœ… í†µí•© ì™„ë£Œ\n",
      "\n",
      "\n",
      "=================================================================\n",
      "ðŸ’¾ Agent 4 ê²°ê³¼ ì €ìž¥ ì™„ë£Œ\n",
      "=================================================================\n",
      "íŒŒì¼ëª…: agent4_integrated_20251104_110325.txt\n",
      "\n",
      "\n",
      "=================================================================\n",
      "ðŸ“„ í†µí•©ëœ Introduction (ì „ì²´)\n",
      "=================================================================\n",
      "\n",
      "Working memory is a central component of cognitive functionality, responsible for the transient holding and manipulation of information to support complex reasoning and purposeful behavior [Cowan, 2014]. It is essential for various high-level cognitive tasks including language processing, problem-solving, and planning. Dysfunctions in working memory are commonly associated with psychiatric conditions such as schizophrenia, ADHD, and depression, emphasizing its clinical importance [Goldman-Rakic, 1994; Kofler et al., 2011]. Thus, investigating the neural mechanisms underlying working memory remains a focus in both cognitive neuroscience and clinical research.\n",
      "\n",
      "Historical analyses of patients with damage to the prefrontal cortex (PFC) reveal significant impairments in working memory maintenance, highlighting the PFC as a critical neural substrate [Pribram et al., 1964]. Functional MRI studies further indicate persistent PFC activation during working memory tasks, suggesting its role in regulating attention and control rather than mere storage [Curtis & Dâ€™Esposito, 2003]. However, recent multivoxel pattern analysis (MVPA) research shows that sensory areas instead may retain the encoded information during working memory tasks, casting doubt on the PFC's role in storage [Harrison & Tong, 2009; Riggall & Postle, 2012]. \n",
      "\n",
      "A reconciliatory perspective posits a distributed network model, wherein the complexity of information abstraction determines its representation ranging from the sensory cortex to the PFC [Christophel et al., 2017]. The posterior parietal cortex (PPC), along with the PFC, figures prominently in this network, supporting the maintenance of abstract information representations. Studies via MVPA disclose the ability to decode information not only from sensory cortices but also from the PPC, reinforcing its integrative role in working memory [Christophel et al., 2017; Schmidt & Blankenburg, 2018].\n",
      "\n",
      "In realistic scenarios, working memory must resist distraction while sustaining target information, a task predominantly assigned to higher cognitive areas involved in attentional regulation and inhibitory control. The PPC, particularly, is implicated in maintaining abstract representations resilient to sensory interference [Bettencourt & Xu, 2016]. Studies indicate that working memory representations in the PPC remain stable even in the presence of distractors, while those in sensory regions are disrupted, advocating for a role in generalizing memory content rather than specific sensory detail processing [Lorenc et al., 2018; Deutsch et al., 2023]. \n",
      "\n",
      "Despite these insights, conclusively defining the causal implication of PPC in managing distractions within working memory using fMRI alone is challenging. Thus, our study leverages transcranial magnetic stimulation (TMS) to probe the causal relationship of the PPC in working memory, particularly under distraction [Liu et al., 2024]. While explorations into TMS to test working memory usually emphasize the PFC, a direct inspection of the PPC's role in distraction resistance is lacking [Hamidi et al., 2008]. We aim to fill this gap by applying TMS to the superior parietal cortex in varying task conditions to observe consequent changes in working memory performance. Structural MRI and fMRI data will refine our understanding of individual anatomical variance and stimulation effects, paving the way for advancements in targeted cognitive interventions.\n",
      "\n",
      "=================================================================\n",
      "ðŸ“Š í†µê³„\n",
      "=================================================================\n",
      "ì „ì²´ ê¸¸ì´: 3456 ê¸€ìž\n",
      "ë‹¨ì–´ ìˆ˜: ì•½ 480 ë‹¨ì–´\n",
      "ìž…ë ¥ (ì‚¬ìš©ìž): 5308 ê¸€ìž\n",
      "ìž…ë ¥ (íŒŒì´í”„ë¼ì¸): 6532 ê¸€ìž\n",
      "ì €ìž¥ íŒŒì¼: agent4_integrated_20251104_110325.txt\n"
     ]
    }
   ],
   "source": [
    "# ===================================\n",
    "# ì‚¬ìš©ìž ìž‘ì„± Introduction íŒŒì¼ ê²½ë¡œ\n",
    "# ===================================\n",
    "# ì—¬ê¸°ì— ì‚¬ìš©ìžê°€ ìž‘ì„±í•œ Introduction íŒŒì¼ ê²½ë¡œë¥¼ ìž…ë ¥í•˜ì„¸ìš”\n",
    "# ì˜ˆ: user_intro_file = \"my_introduction.txt\"\n",
    "user_intro_file = '/Users/he2ryoo/Documents/GitHub/ejung-ryoo/HW6/user_introduction/revised_introduction.txt'  # íŒŒì¼ ê²½ë¡œë¥¼ ìž…ë ¥í•˜ê±°ë‚˜ Noneìœ¼ë¡œ ë‘ê³  ì§ì ‘ ìž…ë ¥\n",
    "\n",
    "# íŒŒì¼ì—ì„œ ì½ê¸° ë˜ëŠ” ì§ì ‘ ìž…ë ¥\n",
    "if user_intro_file and os.path.exists(user_intro_file):\n",
    "    with open(user_intro_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        user_introduction_text = f.read()\n",
    "    print(f\"âœ… ì‚¬ìš©ìž ìž‘ì„± Introduction ë¡œë“œ: {user_intro_file}\")\n",
    "else:\n",
    "    print(\"âš ï¸ ì‚¬ìš©ìž ìž‘ì„± Introduction íŒŒì¼ì´ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "    print(\"í…ìŠ¤íŠ¸ë¥¼ ì§ì ‘ ìž…ë ¥í•˜ê±°ë‚˜, 'user_intro_file' ë³€ìˆ˜ì— íŒŒì¼ ê²½ë¡œë¥¼ ì§€ì •í•˜ì„¸ìš”.\\n\")\n",
    "    \n",
    "    # ì§ì ‘ ìž…ë ¥ (ì—¬ëŸ¬ ì¤„)\n",
    "    print(\"ì‚¬ìš©ìž ìž‘ì„± Introductionì„ ìž…ë ¥í•˜ì„¸ìš” (ìž…ë ¥ ì™„ë£Œ í›„ Ctrl+D ë˜ëŠ” ë¹ˆ ì¤„ 3ë²ˆ):\")\n",
    "    print(\"=\"*65)\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "# Agent 3.5 ê²°ê³¼ ë¡œë“œ\n",
    "try:\n",
    "    with open(logic_revised_filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        pipeline_introduction_text = f.read()\n",
    "    print(f\"âœ… Agent 3.5 ê²°ê³¼ ë¡œë“œ: {logic_revised_filename}\")\n",
    "except (NameError, FileNotFoundError):\n",
    "    print(\"âš ï¸ Agent 3.5 ê²°ê³¼ íŒŒì¼ì„ ì°¾ëŠ” ì¤‘...\")\n",
    "    import glob\n",
    "    logic_revised_files = glob.glob(\"agent3.5_logic_revised_*.txt\")\n",
    "    if logic_revised_files:\n",
    "        logic_revised_files.sort(reverse=True)\n",
    "        logic_revised_filename = logic_revised_files[0]\n",
    "        with open(logic_revised_filename, \"r\", encoding=\"utf-8\") as f:\n",
    "            pipeline_introduction_text = f.read()\n",
    "        print(f\"âœ… ê°€ìž¥ ìµœê·¼ Agent 3.5 ê²°ê³¼ ë¡œë“œ: {logic_revised_filename}\")\n",
    "    else:\n",
    "        raise FileNotFoundError(\"Agent 3.5 ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Agent 3.5ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
    "\n",
    "# Agent 1 ê²€ìƒ‰ ê²°ê³¼ ë¡œë“œ (ì„ íƒì‚¬í•­)\n",
    "search_result_for_integration = None\n",
    "try:\n",
    "    import glob\n",
    "    json_files = glob.glob(\"papers_search_*.json\")\n",
    "    if json_files:\n",
    "        json_files.sort(reverse=True)\n",
    "        with open(json_files[0], \"r\", encoding=\"utf-8\") as f:\n",
    "            search_result_for_integration = json.load(f)\n",
    "        print(f\"âœ… Agent 1 ê²€ìƒ‰ ê²°ê³¼ ë¡œë“œ: {json_files[0]}\")\n",
    "except:\n",
    "    print(\"â„¹ï¸ Agent 1 ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (ì„ íƒì‚¬í•­)\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Agent 4 ì‹¤í–‰\n",
    "integrated_introduction = user_pipeline_integrator_agent(\n",
    "    user_introduction_text,\n",
    "    pipeline_introduction_text,\n",
    "    search_result_for_integration\n",
    ")\n",
    "\n",
    "# íƒ€ìž„ìŠ¤íƒ¬í”„ ìƒì„±\n",
    "timestamp_agent4 = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ìž¥\n",
    "integrated_filename = f\"agent4_integrated_{timestamp_agent4}.txt\"\n",
    "with open(integrated_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(integrated_introduction)\n",
    "\n",
    "print(\"\\n\" + \"=\"*65)\n",
    "print(\"ðŸ’¾ Agent 4 ê²°ê³¼ ì €ìž¥ ì™„ë£Œ\")\n",
    "print(\"=\"*65)\n",
    "print(f\"íŒŒì¼ëª…: {integrated_filename}\\n\")\n",
    "\n",
    "# ì „ì²´ ì¶œë ¥\n",
    "print(\"\\n\" + \"=\"*65)\n",
    "print(\"ðŸ“„ í†µí•©ëœ Introduction (ì „ì²´)\")\n",
    "print(\"=\"*65 + \"\\n\")\n",
    "print(integrated_introduction)\n",
    "\n",
    "print(\"\\n\" + \"=\"*65)\n",
    "print(\"ðŸ“Š í†µê³„\")\n",
    "print(\"=\"*65)\n",
    "print(f\"ì „ì²´ ê¸¸ì´: {len(integrated_introduction)} ê¸€ìž\")\n",
    "print(f\"ë‹¨ì–´ ìˆ˜: ì•½ {len(integrated_introduction.split())} ë‹¨ì–´\")\n",
    "print(f\"ìž…ë ¥ (ì‚¬ìš©ìž): {len(user_introduction_text)} ê¸€ìž\")\n",
    "print(f\"ìž…ë ¥ (íŒŒì´í”„ë¼ì¸): {len(pipeline_introduction_text)} ê¸€ìž\")\n",
    "print(f\"ì €ìž¥ íŒŒì¼: {integrated_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 9. Agent 5: ìµœì¢… ë¬¸ì²´ ì ê²€ ì—ì´ì „íŠ¸\n",
    "\n",
    "## ðŸ“ í•™ìˆ ì  ê¸€ì“°ê¸° ê·œì¹™ ì ìš©\n",
    "\n",
    "### ìž…ë ¥ ìš°ì„ ìˆœìœ„:\n",
    "1. **Agent 4 í†µí•© ê²°ê³¼** (`agent4_integrated_*.txt`) - ìµœìš°ì„ \n",
    "2. **Agent 3.5 ë…¼ë¦¬ ê°œì„  ê²°ê³¼** (`agent3.5_logic_revised_*.txt`) - Agent 4 ì—†ì„ ì‹œ\n",
    "3. **Agent 2 ì´ˆì•ˆ** (`agent2_introduction_draft_*.txt`) - ëŒ€ì²´\n",
    "\n",
    "### ìž‘ë™ ë°©ì‹:\n",
    "\n",
    "#### **1. í•™ìˆ ì  ê¸€ì“°ê¸° ê·œì¹™ ì ìš©**\n",
    "\n",
    "ì´ ê·œì¹™ë“¤ì€ `week9` í´ë”ì˜ `02_translate.py`ì™€ `03_revise.py`ì—ì„œ ì‚¬ìš©ëœ ê²ƒê³¼ ë™ì¼í•©ë‹ˆë‹¤.\n",
    "\n",
    "**ì£¼ìš” ê·œì¹™ 25+ê°œ:**\n",
    "\n",
    "- **Actions in verbs** (ë™ì‚¬ ì¤‘ì‹¬ í‘œí˜„)\n",
    "  - ë‚˜ì¨: \"The regulation of memory is important\"\n",
    "  - ì¢‹ìŒ: \"Regulating memory is important\"\n",
    "\n",
    "- **Characters in subjects** (ì£¼ì–´ì— í–‰ìœ„ìž)\n",
    "  - ë‚˜ì¨: \"Identification of features will require several genomes\"\n",
    "  - ì¢‹ìŒ: \"Several genomes are needed to identify features\"\n",
    "\n",
    "- **Keep subjects near verbs** (ì£¼ì–´-ë™ì‚¬ ê·¼ì ‘)\n",
    "  - ë‚˜ì¨: \"Peanuts, shrimp, almonds, milk, and wheat all represent things people are allergic to\"\n",
    "  - ì¢‹ìŒ: \"People are commonly allergic to peanuts, shrimp, milk, and wheat\"\n",
    "\n",
    "- **Use passive voice judiciously** (ëŠ¥ë™íƒœ ìš°ì„ )\n",
    "  - ì¼ë°˜ì ìœ¼ë¡œ ì¢‹ìŒ: \"Researchers conducted the experiment\"\n",
    "  - ê°ê´€ì„± í•„ìš”ì‹œ: \"The experiment was conducted\"\n",
    "\n",
    "- **Concise expressions** (ê°„ê²°í•œ í‘œí˜„)\n",
    "\n",
    "| ë‚˜ìœ í‘œí˜„ | ì¢‹ì€ í‘œí˜„ |\n",
    "|---------|--------|\n",
    "| the question as to whether | whether |\n",
    "| there is no doubt but that | doubtless |\n",
    "| in a careful manner | carefully |\n",
    "| a large majority of | most |\n",
    "| has the capacity to | can |\n",
    "| whether or not | whether |\n",
    "| due to the fact that | because |\n",
    "| in the event that | if |\n",
    "| at this point in time | now |\n",
    "| prior to | before |\n",
    "| subsequent to | after |\n",
    "| plays a key role in | is essential to |\n",
    "\n",
    "#### **2. ì¼ê´€ì„± ìœ ì§€**\n",
    "- Agent 4ì—ì„œ í†µí•©ëœ ì‚¬ìš©ìž ë…¼ë¦¬ ì „ê°œ ìœ ì§€\n",
    "- ì¶”ê°€ëœ ì¸ìš©ì˜ í˜•ì‹ í†µì¼\n",
    "- ë¬¸ë‹¨ ê°„ ìžì—°ìŠ¤ëŸ¬ìš´ ì—°ê²°\n",
    "\n",
    "#### **3. ìµœì¢… ì ê²€**\n",
    "- ë¬¸ë²• ì˜¤ë¥˜ ìˆ˜ì •\n",
    "- í‘œí˜„ì˜ ëª…í™•ì„± ê°œì„ \n",
    "- í•™ìˆ  ë…¼ë¬¸ì— ì í•©í•œ í†¤ ìœ ì§€\n",
    "- ë¬¸ë‹¨ ì‘ì§‘ì„± ê°•í™”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë¬¸ì²´ ë° ë‚´ìš© ì ê²€ ì—ì´ì „íŠ¸ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "def style_checker_agent(\n",
    "    introduction: str,\n",
    "    logic_report: Dict[str, Any] = None\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    ë¬¸ì²´ ë° ë‚´ìš© ì ê²€ ì—ì´ì „íŠ¸\n",
    "    \n",
    "    Args:\n",
    "        introduction (str): ìž‘ì„±ëœ Introduction\n",
    "        logic_report (dict): ë…¼ë¦¬ ì ê²€ ê²°ê³¼ (ì„ íƒ)\n",
    "    \n",
    "    Returns:\n",
    "        str: ìˆ˜ì •ëœ Introduction\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ðŸ“ ë¬¸ì²´ ë° ë‚´ìš© ì ê²€ ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘...\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    logic_feedback = \"\"\n",
    "    if logic_report:\n",
    "        logic_feedback = f\"\"\"\n",
    "\\nLogic Check Report:\n",
    "{logic_report['report']}\n",
    "\n",
    "Please address the flagged issues while revising.\n",
    "Remove or rewrite sentences with low relevance scores.\n",
    "\"\"\"\n",
    "    \n",
    "    style_prompt = f\"\"\"\n",
    "You are an academic editor specializing in cognitive neuroscience and psychology.\n",
    "\n",
    "Introduction Text:\n",
    "{introduction}\n",
    "{logic_feedback}\n",
    "\n",
    "Your task:\n",
    "Revise the text to make it more natural, fluent, and academically appropriate, while preserving all original meaning and content.\n",
    "\n",
    "Editing goals:\n",
    "â€¢ Improve flow and coherence between sentences\n",
    "â€¢ Replace casual or repetitive phrases with concise academic expressions\n",
    "â€¢ Avoid generic transitions (\"In addition\", \"Moreover\") unless necessary; vary sentence openings\n",
    "â€¢ Keep the tone formal, objective, and publication-ready\n",
    "\n",
    "Additional stylistic and structural rules:\n",
    "1. Put actions in verbs rather than nouns\n",
    "   - Prefer \"to regulate\" over \"regulation\"\n",
    "   - Prefer \"to delineate\" over \"delineation\"\n",
    "\n",
    "2. Put characters (agents) in subjects\n",
    "   - Instead of: \"Identification of features will require several genomes\"\n",
    "   - Prefer: \"Several genomes are needed to identify features\"\n",
    "\n",
    "3. Keep subjects near verbs\n",
    "   - Instead of: \"Peanuts, shrimp, almonds, milk, and wheat all represent things people are allergic to\"\n",
    "   - Prefer: \"People are commonly allergic to peanuts, shrimp, milk, and wheat\"\n",
    "\n",
    "4. Use passive voice judiciously\n",
    "   - Favor active voice for clarity\n",
    "   - Retain passive when it enhances objectivity\n",
    "\n",
    "5. Ensure paragraph cohesion\n",
    "   - First and last sentences should align in theme\n",
    "\n",
    "6. Use concise academic alternatives:\n",
    "   - \"whether\" instead of \"the question as to whether\"\n",
    "   - \"doubtless\" instead of \"there is no doubt but that\"\n",
    "   - \"carefully\" instead of \"in a careful manner\"\n",
    "   - \"most\" instead of \"a large majority of\"\n",
    "   - \"can\" instead of \"has the capacity to\"\n",
    "   - \"whether\" instead of \"whether or not\"\n",
    "   - \"agree\" instead of \"are in agreement\"\n",
    "   - \"before\" instead of \"prior to\"\n",
    "   - \"after\" instead of \"subsequent to\"\n",
    "   - \"now\" instead of \"at this point in time\"\n",
    "   - \"because\" instead of \"due to the fact that\"\n",
    "   - \"if\" instead of \"in the event that\"\n",
    "   - \"unique\" instead of \"nearly unique\"\n",
    "   - \"is essential to\" instead of \"plays a key role in\"\n",
    "   - \"both were affected\" instead of \"both cultures were equally affected\"\n",
    "\n",
    "Output:\n",
    "A revised version ready for submission to a top-tier academic journal.\n",
    "Maintain all citations in (Author, Year) format.\n",
    "Do not remove citations or change their format.\n",
    "\"\"\"\n",
    "    \n",
    "    print(\"ðŸ”„ ë¬¸ì²´ ì ê²€ ë° ìˆ˜ì • ì¤‘ (1-2ë¶„ ì†Œìš”)...\")\n",
    "    \n",
    "    style_response = client.chat_completions_create(\n",
    "        messages=[{\"role\": \"user\", \"content\": style_prompt}],\n",
    "        tools=[],\n",
    "        max_turns=1\n",
    "    )\n",
    "    \n",
    "    revised_introduction = style_response.choices[0].message.content\n",
    "    \n",
    "    print(\"âœ… ë¬¸ì²´ ì ê²€ ì™„ë£Œ\\n\")\n",
    "    \n",
    "    return revised_introduction\n",
    "\n",
    "print(\"âœ… ë¬¸ì²´ ë° ë‚´ìš© ì ê²€ ì—ì´ì „íŠ¸ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Agent 5 ì‹¤í–‰í•˜ê¸°\n",
    "\n",
    "ì•„ëž˜ ì…€ì„ ì‹¤í–‰í•˜ì—¬ ìµœì¢… ë¬¸ì²´ ì ê²€ì„ ìˆ˜í–‰í•˜ì„¸ìš”.\n",
    "\n",
    "**ì†Œìš” ì‹œê°„:** ì•½ 1-2ë¶„\n",
    "\n",
    "### ìžë™ ìž…ë ¥ ë¡œë“œ (ìš°ì„ ìˆœìœ„):\n",
    "1. **Agent 4 í†µí•© ê²°ê³¼** (`agent4_integrated_*.txt`) â† ìµœìš°ì„ \n",
    "2. **Agent 3.5 ë…¼ë¦¬ ê°œì„  ê²°ê³¼** (`agent3.5_logic_revised_*.txt`)\n",
    "3. **Agent 2 ì´ˆì•ˆ** (`agent2_introduction_draft_*.txt`)\n",
    "\n",
    "### ì¶œë ¥:\n",
    "- ì¶œíŒ ê°€ëŠ¥í•œ ìˆ˜ì¤€ì˜ ìµœì¢… Introduction\n",
    "- í•™ìˆ ì  ê¸€ì“°ê¸° ê·œì¹™ 25+ê°œ ì ìš©\n",
    "- ë¬¸ì²´ ë° í‘œí˜„ ê°œì„  ì™„ë£Œ\n",
    "- íŒŒì¼ ì €ìž¥: `agent5_final_[timestamp].txt`\n",
    "- í™”ë©´ ì¶œë ¥: ì „ì²´ í…ìŠ¤íŠ¸\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agent 4 í†µí•© ê²°ê³¼ ë¡œë“œ: agent4_integrated_20251104_110325.txt\n",
      "\n",
      "\n",
      "============================================================\n",
      "ðŸ“ ë¬¸ì²´ ë° ë‚´ìš© ì ê²€ ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘...\n",
      "============================================================\n",
      "\n",
      "ðŸ”„ ë¬¸ì²´ ì ê²€ ë° ìˆ˜ì • ì¤‘ (1-2ë¶„ ì†Œìš”)...\n",
      "âœ… ë¬¸ì²´ ì ê²€ ì™„ë£Œ\n",
      "\n",
      "\n",
      "=================================================================\n",
      "ðŸ’¾ Agent 5 ê²°ê³¼ ì €ìž¥ ì™„ë£Œ\n",
      "=================================================================\n",
      "íŒŒì¼ëª…: agent5_final_20251104_110432.txt\n",
      "\n",
      "\n",
      "=================================================================\n",
      "ðŸ“„ ìµœì¢… Introduction (ì „ì²´)\n",
      "=================================================================\n",
      "\n",
      "Working memory is integral to cognitive function, facilitating the temporary retention and manipulation of information necessary for complex reasoning and purposeful behavior (Cowan, 2014). It underpins various high-level cognitive tasks, including language processing, problem-solving, and planning. Dysfunctional working memory is often linked to psychiatric conditions such as schizophrenia, ADHD, and depression, underscoring its clinical relevance (Goldman-Rakic, 1994; Kofler et al., 2011). Consequently, understanding the neural mechanisms underpinning working memory remains a focal point in cognitive neuroscience and clinical research.\n",
      "\n",
      "Historical analyses of patients with prefrontal cortex (PFC) damage reveal significant impairments in working memory maintenance, indicating the PFC's critical involvement (Pribram et al., 1964). Functional MRI studies further demonstrate sustained PFC activation during working memory tasks, suggesting its role in attention regulation and control rather than solely in storage (Curtis & Dâ€™Esposito, 2003). In contrast, recent multivoxel pattern analysis (MVPA) research suggests that sensory areas may actually retain the encoded information during working memory tasks, challenging the PFC's traditional role as a storage site (Harrison & Tong, 2009; Riggall & Postle, 2012).\n",
      "\n",
      "A reconciliatory perspective proposes a distributed network model, wherein the complexity of information abstraction dictates its representation from sensory cortex to PFC (Christophel et al., 2017). Within this network, the posterior parietal cortex (PPC) plays a significant role alongside the PFC, supporting the maintenance of abstract information representations. MVPA studies confirm that information can be decoded not only from sensory cortices but also from the PPC, underscoring its integrative function in working memory (Christophel et al., 2017; Schmidt & Blankenburg, 2018).\n",
      "\n",
      "In real-world contexts, working memory must resist distractions while sustaining target information, a function predominantly managed by higher cognitive areas involved in attentional regulation and inhibitory control. The PPC is particularly implicated in maintaining abstract representations resilient to sensory interference (Bettencourt & Xu, 2016). Evidence indicates that working memory representations in the PPC remain stable despite distractors, while those in sensory regions are disrupted, suggesting its role in generalizing memory content rather than processing specific sensory details (Lorenc et al., 2018; Deutsch et al., 2023).\n",
      "\n",
      "Definitively determining the PPC's causal role in managing distractions within working memory using fMRI alone presents challenges. To address this, our study employs transcranial magnetic stimulation (TMS) to investigate the PPC's causal involvement in working memory, particularly under distraction (Liu et al., 2024). Although TMS studies traditionally focus on the PFC, direct examination of the PPC's role in distraction resistance is scarce (Hamidi et al., 2008). We aim to address this gap by applying TMS to the superior parietal cortex under various task conditions to assess changes in working memory performance. Structural MRI and fMRI data will enhance our understanding of individual anatomical variation and the effects of stimulation, paving the way for targeted cognitive interventions.\n",
      "\n",
      "=================================================================\n",
      "ðŸ“Š í†µê³„\n",
      "=================================================================\n",
      "ì „ì²´ ê¸¸ì´: 3366 ê¸€ìž\n",
      "ë‹¨ì–´ ìˆ˜: ì•½ 454 ë‹¨ì–´\n",
      "ìž…ë ¥ ì†ŒìŠ¤: Agent 4 (Integrated)\n",
      "ì €ìž¥ íŒŒì¼: agent5_final_20251104_110432.txt\n"
     ]
    }
   ],
   "source": [
    "# Agent 4 í†µí•© ê²°ê³¼ íŒŒì¼ ì½ê¸° (ìš°ì„ ìˆœìœ„: Agent 4 > Agent 3.5 > Agent 2)\n",
    "introduction_for_style_check = None\n",
    "source_agent = None\n",
    "\n",
    "# 1ìˆœìœ„: Agent 4 í†µí•© ê²°ê³¼\n",
    "try:\n",
    "    with open(integrated_filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        introduction_for_style_check = f.read()\n",
    "    print(f\"âœ… Agent 4 í†µí•© ê²°ê³¼ ë¡œë“œ: {integrated_filename}\")\n",
    "    source_agent = \"Agent 4 (Integrated)\"\n",
    "except (NameError, FileNotFoundError):\n",
    "    print(\"âš ï¸ Agent 4 ê²°ê³¼ íŒŒì¼ì„ ì°¾ëŠ” ì¤‘...\")\n",
    "    import glob\n",
    "    integrated_files = glob.glob(\"agent4_integrated_*.txt\")\n",
    "    if integrated_files:\n",
    "        integrated_files.sort(reverse=True)\n",
    "        integrated_filename = integrated_files[0]\n",
    "        with open(integrated_filename, \"r\", encoding=\"utf-8\") as f:\n",
    "            introduction_for_style_check = f.read()\n",
    "        print(f\"âœ… ê°€ìž¥ ìµœê·¼ Agent 4 í†µí•© ê²°ê³¼ ë¡œë“œ: {integrated_filename}\")\n",
    "        source_agent = \"Agent 4 (Integrated)\"\n",
    "\n",
    "# 2ìˆœìœ„: Agent 3.5 ë…¼ë¦¬ ê°œì„  ê²°ê³¼\n",
    "if introduction_for_style_check is None:\n",
    "    print(\"â„¹ï¸ Agent 4 ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. Agent 3.5 ê²°ê³¼ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "    try:\n",
    "        import glob\n",
    "        logic_revised_files = glob.glob(\"agent3.5_logic_revised_*.txt\")\n",
    "        if logic_revised_files:\n",
    "            logic_revised_files.sort(reverse=True)\n",
    "            with open(logic_revised_files[0], \"r\", encoding=\"utf-8\") as f:\n",
    "                introduction_for_style_check = f.read()\n",
    "            print(f\"âœ… Agent 3.5 ê²°ê³¼ ë¡œë“œ: {logic_revised_files[0]}\")\n",
    "            source_agent = \"Agent 3.5 (Logic Revised)\"\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# 3ìˆœìœ„: Agent 2 ì´ˆì•ˆ\n",
    "if introduction_for_style_check is None:\n",
    "    print(\"â„¹ï¸ Agent 3.5 ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. Agent 2 ì´ˆì•ˆì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "    import glob\n",
    "    draft_files = glob.glob(\"agent2_introduction_draft_*.txt\")\n",
    "    if draft_files:\n",
    "        draft_files.sort(reverse=True)\n",
    "        with open(draft_files[0], \"r\", encoding=\"utf-8\") as f:\n",
    "            introduction_for_style_check = f.read()\n",
    "        print(f\"âœ… Agent 2 ì´ˆì•ˆ ë¡œë“œ: {draft_files[0]}\")\n",
    "        source_agent = \"Agent 2 (Draft)\"\n",
    "    else:\n",
    "        raise FileNotFoundError(\"Agent 2, 3.5, ë˜ëŠ” 4 ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Agent 5 ì‹¤í–‰ (ê¸°ì¡´ style_checker_agent ì‚¬ìš©)\n",
    "final_introduction = style_checker_agent(introduction_for_style_check, None)\n",
    "\n",
    "# íƒ€ìž„ìŠ¤íƒ¬í”„ ìƒì„±\n",
    "timestamp_agent5 = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ìž¥\n",
    "final_filename = f\"agent5_final_{timestamp_agent5}.txt\"\n",
    "with open(final_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(final_introduction)\n",
    "\n",
    "print(\"\\n\" + \"=\"*65)\n",
    "print(\"ðŸ’¾ Agent 5 ê²°ê³¼ ì €ìž¥ ì™„ë£Œ\")\n",
    "print(\"=\"*65)\n",
    "print(f\"íŒŒì¼ëª…: {final_filename}\\n\")\n",
    "\n",
    "# ì „ì²´ ì¶œë ¥\n",
    "print(\"\\n\" + \"=\"*65)\n",
    "print(\"ðŸ“„ ìµœì¢… Introduction (ì „ì²´)\")\n",
    "print(\"=\"*65 + \"\\n\")\n",
    "print(final_introduction)\n",
    "\n",
    "print(\"\\n\" + \"=\"*65)\n",
    "print(\"ðŸ“Š í†µê³„\")\n",
    "print(\"=\"*65)\n",
    "print(f\"ì „ì²´ ê¸¸ì´: {len(final_introduction)} ê¸€ìž\")\n",
    "print(f\"ë‹¨ì–´ ìˆ˜: ì•½ {len(final_introduction.split())} ë‹¨ì–´\")\n",
    "print(f\"ìž…ë ¥ ì†ŒìŠ¤: {source_agent}\")\n",
    "print(f\"ì €ìž¥ íŒŒì¼: {final_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
